---
    title: "People"
---

## Primary academic staff and fellows

| Name | Project/interests/keywords |
| --- | --- |
| [Dr Mathieu Barthet](http://www.eecs.qmul.ac.uk/people/view/4808/dr-mathieu-barthet)  <br>Senior Lecturer in Digital Media | Music information research, Internet of musical things, Extended reality, New interfaces for musical expression, Semantic audio, Music perception (timbre, emotions), Audience-Performer interaction, Participatory art |
| [Dr Emmanouil Benetos](http://www.eecs.qmul.ac.uk/people/view/4741/dr-emmanouil-benetos)  <br>Reader in Machine Listening, Turing Fellow | Machine listening, music information retrieval, computational sound scene analysis, machine learning for audio analysis, language models for music and audio, computational musicology |
| [Prof. Simon Dixon](http://www.eecs.qmul.ac.uk/~simond/)  <br>Professor of Computer Science, Deputy Director of C4DM, Director of the AIM CDT, Turing Fellow | Music informatics, music signal processing, artificial intelligence, music cognition; extraction of musical content (e.g. rhythm, harmony, intonation) from audio signals: beat tracking, audio alignment, chord and note transcription, singing intonation; using signal processing approaches, probabilistic models, and deep learning. |
| [Dr George Fazekas](http://eecs.qmul.ac.uk/~gyorgyf)  <br>Senior Lecturer | Semantic Audio, Music Information Retrieval, Semantic Web for Music, Machine Learning and Data Science, Music Emotion Recognition, Interactive music sytems (e.g. intellignet editing, audio production and performance systems) |
| [Dr Aidan Hogg](https://aidanhogg.uk/)  <br>Lecturer in Computer Science | spatial and immersive audio, music signal processing, machine learning for audio, music information retrieval |
| [Prof Andrew McPherson](http://www.eecs.qmul.ac.uk/~andrewm)  <br>Professor of Musical Interaction | new interfaces for musical expression, augmented instruments, performance study, human-computer interaction, embedded hardware |
| [Dr Johan Pauwels](http://www.eecs.qmul.ac.uk/people/view/50775/johan-pauwels)  <br>Lecturer in Audio Signal Processing | automatic music labelling, music information retrieval, music signal processing, machine learning for audio, chord/key/structure (joint) estimation, instrument identification, multi-track/channel audio, music transcription, graphical models, big data science |
| [Prof. Joshua D Reiss](http://www.eecs.qmul.ac.uk/~josh/)  <br>Professor of Audio Engineering | sound engineering, intelligent audio production, sound synthesis, audio effects, automatic mixing |
| [Dr Charalampos Saitis](http://eecs.qmul.ac.uk/profiles/saitischaralampos.html)  <br>Lecturer in Digital Music Processing, Turing Fellow | Communication acoustics, crossmodal correspondences, sound synthesis, cognitive audio, musical haptics |
| [Prof Mark Sandler](http://www.eecs.qmul.ac.uk/people/view/3114/prof-mark-sandler)  <br>C4DM Director, Turing Fellow, Royal Society Wolfson Research Merit award holder | Digital Signal Processing, Digital Audio, Music Informatics, Audio Features, Semantic Audio, Immersive Audio, Studio Science, Music Data Science, Music Linked Data. |
| [Dr Tony Stockman](http://www.eecs.qmul.ac.uk/people/view/3026/dr-tony-stockman)  <br>Senior Lecturer | Interaction Design, auditory displays, Data Sonification, Collaborative Systems, Cross-modal Interaction, Assistive Technology, Accessibility |
| [Dr Lin Wang](http://www.eecs.qmul.ac.uk/~linwang/)  <br>Lecturer in Applied Data Science and Signal Processing | signal processing; machine learning; robot perception |
| [Dr Anna Xambó](https://annaxambo.me/)  <br>Senior Lecturer in Sound and Music Computing | new interfaces for musical expression, performance study, human-computer interaction, interaction design |

## Associate academic staff and fellows

| Name | Project/interests/keywords |
| --- | --- |
| [Prof Pat Healey](http://www.eecs.qmul.ac.uk/%7Eph/)  <br>Professor of Human Interaction, Turing Fellow |     |
| [Dr Marcus Pearce](https://www.marcus-pearce.com)  <br>Senior Lecturer in Sound & Music Processing | Music Cognition, Auditory Perception, Empirical Aesthetics, Statistical Learning, Probabilistic Modelling. |
| [Prof Matthew Purver](http://www.eecs.qmul.ac.uk/~mpurver/)  <br>Professor of Computational Linguistics, Turing Fellow | computational linguistics including models of language and music |
| [Prof Geraint Wiggins](https://ai.vub.ac.be/team/geraint-wiggins/?utm_source=www.google.com&utm_medium=organic&utm_campaign=Google&referrer-analytics=1)  <br>Professor of Computational Creativity | Computational Creativity, Artificial Intelligence, Music Cognition |

## Research support staff

| Name | Project/interests/keywords |
| --- | --- |
| [Alvaro Bort](http://eecs.qmul.ac.uk/profiles/bortalvaro.html)  <br>Research Programme Manager | Projects: UKRI Centre for Doctoral Training in Artificial Intelligence and Music, New Frontiers in Music Information Processing (MIP-Frontiers) |
| [Jonathan Winfield](http://eecs.qmul.ac.uk/profiles/winfieldjonathan.html)  <br>Research Programme Manager | Project: Centre for Doctoral Training in Media and Arts Technology |

## Postdoctoral research assistants

| Name | Project/interests/keywords |
| --- | --- |
| Dr Jacob Harrison | Bridging the gap: visually impaired and sighted music industry professionals working side by side |
| [Dr Yuanyuan Liu](http://eecs.qmul.ac.uk/profiles/liuyuanyuan.html) | Project: Digital Platforms for Craft in the UK and China |

## Research assistants

| Name | Project/interests/keywords |
| --- | --- |
| [Sungkyun Chang](http://eecs.qmul.ac.uk/profiles/sungkyun-chang.html) | Deep learning technologies for multi-instrument automatic music transcription |

## Research students

| Name | Project/interests/keywords |
| --- | --- |
| [Berker Banar](http://eecs.qmul.ac.uk/profiles/banarberker.html) | Towards Composing Contemporary Classical Music using Generative Deep Learning |
| Adán Benito | Beyond the fret: gesture analysis on fretted instruments and its applications to instrument augmentation |
| [Aditya Bhattacharjee](https://www.linkedin.com/in/adibh/) | Self-supervision in Audio Fingerprinting |
| James Bolt | Intelligent audio and music editing with deep learning |
| Gary Bromham | The role of nostalga in music production |
| Carey Bunks | Cover Song Identification |
| [Marco Comunità](http://eecs.qmul.ac.uk/profiles/comunitamarco.html) | Machine learning applied to sound synthesis models |
| Ruby Crocker | Continuous mood recognition in film music |
| [Andrew (Drew) Edwards](http://eecs.qmul.ac.uk/profiles/edwardsandrewcharles.html) | Deep Learning for Jazz Piano: Transcription + Generative Modeling |
| Oluremi Falowo | E-AIM - Embodied Cognition in Intelligent Musical Systems |
| [Corey Ford](http://eecs.qmul.ac.uk/profiles/fordcoreyjohn.html) | Artificial Intelligence for Supporting Musical Creativity and Engagement in Child-Computer Interaction |
| [David Foster](http://eecs.qmul.ac.uk/profiles/fosterdavid.html) | Modelling the Creative Process of Jazz Improvisation |
| Nelly Garcia | An investigation evaluating realism in sound design |
| [Adam Andrew Garrow](https://www.researchgate.net/profile/Adam-Garrow) | : Probabilistic learning of sequential structures in music cognition |
| [Iacopo Ghinassi](https://github.com/Ighina) | Semantic understanding of TV programme content and structure to enable automatic enhancement and adjustment |
| [Max Graf](http://eecs.qmul.ac.uk/profiles/grafmax.html) | PERFORM-AI (Provide Extended Realities for Musical Performance using AI) |
| [Andrea Guidi](https://mat.qmul.ac.uk/students/andrea-guidi) | Design for auditory imagery |
| [Edward Hall](https://mat.qmul.ac.uk/students/edward-hall) | Probabilistic modelling of thematic development and structural coherence in music |
| [Madeline Hamilton](http://eecs.qmul.ac.uk/profiles/hamiltonmadelineann.html) | Improving AI-generated Music with Pleasure Models |
| [Benjamin Hayes](http://eecs.qmul.ac.uk/profiles/hayesbenjaminjames.html) | Perceptually motivated deep learning approaches to creative sound synthesis |
| [Jiawen Huang](http://eecs.qmul.ac.uk/profiles/huangjiawen.html) | Lyrics Alignment For Polyphonic Music |
| [Ilias Ibnyahya](https://ilias-audio.github.io/) | Audio Effects design optimization |
| [Thomas Kaplan](https://kappers.github.io/) | Probabilistic modelling of rhythm perception and production |
| [Harnick Khera](http://eecs.qmul.ac.uk/profiles/kheraharnicksingh.html) | Informed source separation for multi-mic production |
| [Giacomo Lepri](http://www.giacomolepri.com/) | Exploring the role of culture and community in the design of new musical instruments |
| [Yukun Li](http://eecs.qmul.ac.uk/profiles/liyukun.html) | Computational Comparison Between Different Genres of Music in Terms of the Singing Voice |
| [Jinhua Liang](https://jinhualiang.github.io/) | AI for everyday sounds |
| [Lele Liu](http://eecs.qmul.ac.uk/profiles/liulele.html) | Automatic music transcription with end-to-end deep neural networks |
| [Carlos Lordelo](https://cpvlordelo.github.io/) | Instrument modelling to aid polyphonic transcription |
| [Yin-Jyun Luo](http://eecs.qmul.ac.uk/profiles/luoyin-jyun.html) | Industry-scale Machine Listening for Music and Audio Data |
| [Yinghao Ma](https://nicolaus625.github.io/) | Self-supervision in machine listening |
| [Ilaria Manco](http://eecs.qmul.ac.uk/profiles/mancoilaria.html) | Multimodal Deep Learning for Music Information Retrieval |
| [Luca Marinelli](http://eecs.qmul.ac.uk/profiles/marinelliluca.html) | Gender-coded sound: A multimodal data-driven analysis of gender encoding strategies in sound and music for advertising |
| [Andrea Martelloni](http://eecs.qmul.ac.uk/profiles/martelloniandrea-1.html) | Real-Time Gesture Classification on an Augmented Acoustic Guitar using Deep Learning to Improve Extended-Range and Percussive Solo Playing |
| Tyler Howard McIntosh | Expressive Performance Rendering for Music Generation Systems |
| [Christopher Mitcheltree](https://christhetr.ee) | Representation Learning for Audio Production Style and Modulations |
| [Ashley Noel-Hirst](https://ashleynoelhirst.co.uk/) | Latent Spaces for Human-AI music generation |
| [Inês Nolasco](http://eecs.qmul.ac.uk/profiles/nolascoines.html) | Towards an automatic acoustic identification of individuals in the wild |
| [Brendan O'Connor](https://trebolium.github.io/) | Singing Voice Attribute Transformation |
| [Arjun Pankajakshan](https://sites.google.com/view/arjunpc4dm/home) | Computational sound scene analysis |
| [Teresa Pelinski](https://www.teresapelinski.com/) | Sensor mesh as performance interface |
| [Mary Pilataki](https://github.com/marypilataki) | Deep Learning methods for Multi-Instrument Music Transcription |
| [Vjosa Preniqi](http://eecs.qmul.ac.uk/profiles/preniqivjosa.html) | Predicting demographics, personalities, and global values from digital media behaviours |
| [Xavier Riley](http://eecs.qmul.ac.uk/profiles/rileyjohnxavier.html) | Pitch tracking for music applications - beyond 99% accuracy |
| [Eleanor Row](http://eecs.qmul.ac.uk/profiles/roweleanorroxannevictoria.html) | Automatic micro-composition for professional/novice composers using generative models as creativity support tools |
| Sebastián Ruiz | Physiological Responses to Ensemble Interaction |
| [Saurjya Sarkar](http://eecs.qmul.ac.uk/profiles/sarkarsaurjya-1.html) | New perspectives in instrument-based audio source separation |
| [Pedro Sarmento](https://otnemrasordep.github.io/) | Guitar-Oriented Neural Music Generation in Symbolic Format |
| [Dalia Senvaityte](http://eecs.qmul.ac.uk/profiles/senvaitytedalia.html) | Audio Source Separation for Advanced Digital Audio Effects |
| [Bleiz Del Sette](https://comma.eecs.qmul.ac.uk/people/bleiz/) | The Sound of Care: researching the use of Deep Learning and Sonification for the daily support of people with Chronic Primary Pain |
| [Elona Shatri](http://eecs.qmul.ac.uk/profiles/shatrielona-1.html) | Optical music recognition using deep learning |
| [Jordie Shier](https://jordieshier.com/) | Real-time timbral mapping for synthesized percussive performance |
| [Shubhr Singh](http://eecs.qmul.ac.uk/profiles/singhshubhr.html) | Audio Applications of Novel Mathematical Methods in Deep Learning |
| [Christian Steinmetz](https://www.christiansteinmetz.com/) | End-to-end generative modeling of multitrack mixing with non-parallel data and adversarial networks |
| [David Südholt](https://dsuedholt.github.io/) | Machine Learning of Physical Models for Voice Synthesis |
| [Jingjing Tang](http://eecs.qmul.ac.uk/profiles/tangjingjing.html) | End-to-End System Design for Music Style Transfer with Neural Networks |
| Louise Thorpe | Using Signal-informed Source Separation (SISS) principles to improve instrument separation from legacy recordings |
| [Antonella Torrisi](https://www.researchgate.net/profile/Antonella-Torrisi) | Computational analysis of chick vocalisations: from categorisation to live feedback |
| Maryam Torshizi | Music emotion modelling using graph analysis |
| [Cyrus Vahidi](http://eecs.qmul.ac.uk/profiles/vahidicyrus.html) | Perceptual end to end learning for music understanding |
| [Soumya Sai Vanka](http://eecs.qmul.ac.uk/profiles/vankasaisoumya.html) | Music Production Style Transfer and Mix Similarity |
| [Yannis (John) Vasilakis](https://www.linkedin.com/in/yannis-vasilakis-6bb9b11b1/) | Active Learning for Interactive Music Transcription |
| Ningzhi Wang | Generative Models For Music Audio Representation And Understanding |
| James Weaver | Space and Intelligibility of Musical Performance |
| Alexander Williams | User-driven deep music generation in digital audio workstations |
| [Elizabeth Wilson](https://lwlsn.github.io) | Co-creative Algorithmic Composition Based on Models of Affective Response |
| [Chris Winnard](http://eecs.qmul.ac.uk/profiles/winnardchristopherjames.html) | Music Interestingness in the Brain |
| [Lewis Wolstanholme](http://lewiswolstanholme.co.uk) | Meta-Physical Modelling |
| Chengye Wu | Leveraging cross-sensory associations in communication |
| [Chin-Yun Yu](https://yoyololicon.github.io/) | Neural Audio Synthesis with Expressiveness Control |
| [Huan Zhang](http://eecs.qmul.ac.uk/people/profiles/zhanghuan.html) | Computational Modelling of Expressive Piano Performance |
| Jincheng Zhang | Emotion-specific Music Generation Using Deep Learning |
| [Yixiao Zhang](http://eecs.qmul.ac.uk/profiles/zhangyixiao.html) | Machine Learning Methods for Artificial Musicality |

## Visiting academics

| Name | Project/interests/keywords |
| --- | --- |
| [Dr Helen Bear](http://www.eecs.qmul.ac.uk/profiles/bearhelen.html)  <br>Honorary Lecturer | Integrating sound and context recognition for acoustic scene analysis |
| [Dr Matthias Mauch](http://www.matthiasmauch.net/)  <br>Visiting Academic | music transcription (chords, beats, drums, melody, ...), interactive music annotation, singing research, research in the evolution of musical styles |
| [Dr Veronica Morfi](https://scholar.google.co.uk/citations?user=8izRvu4AAAAJ&hl=en) | Machine transcription of wildlife bird sound scenes |
| [Dr Montserrat Pàmies-Vilà](https://iwk.mdw.ac.at/montserrat-pamies-vila/)  <br>University of Music and Performing Arts Vienna | Timbre modelling for non-conventional cello techniques |

## Visitors

| Name | Project/interests/keywords |
| --- | --- |
| [Domenico Stefani](https://domenicostefani.com/)  <br>University of Trento, Italy | Embedded machine learning for smart musical instruments |
