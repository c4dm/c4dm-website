{"componentChunkName":"component---src-templates-news-post-js","path":"/news/2025-10-22.C4DM-Seminar_Nithya_Shikarpur/","result":{"data":{"markdownRemark":{"html":"<h3>C4DM Seminar: Nithya Shikarpur: Towards Generative Modeling and Interactive Performance for Hindustani Music and beyond</h3>\n<hr>\n<h4>QMUL, School of Electronic Engineering and Computer Science</h4>\n<h4>Centre for Digital Music Seminar Series</h4>\n<p><strong>Seminar by:</strong> Nithya Shikarpur</p>\n<p><strong>Date/time:</strong>  Wednesday, 22th October 2025, 3.30pm</p>\n<p><strong>Location:</strong> Hybrid. Peter Landin building, room 4.24</p>\n<p><strong>Teams meeting info:</strong> Meeting ID: 324 267 638 748 , Passcode: 7sV9PL6k</p>\n<h2><b>Title</b>: Towards Generative Modeling and Interactive Performance for Hindustani Music and beyond</h2>\n<p><b>Abstract</b>:\nRecent advances in generative music modeling open up rich avenues for creative exploration and expression. As both a musician and researcher, my work focuses on two interconnected goals: (1) developing generative models that meaningfully engage with the musical context and aesthetics of specific traditions, and (2) designing interactive systems that foster creative collaboration between humans and generative models. First, I will introduce GaMaDHaNi, a hierarchical generative model for Hindustani vocal music.  Through a hierarchical system, modeling pitch contours first followed by spectrograms, GaMaDHaNi captures the microtonal nuances that characterize this tradition. I will further discuss the challenges of conditioning such models on musically relevant parameters such as raga. Second, I will share insights from “cat-in-loop”, a collaborative performance created with the Cat in Black ensemble and my collaborators Weilu Ge and Hugo Garcia. This work explores the creative (mis)use of VampNet, a masked audio transformer model, as a tool for embodied improvisation and human-AI co-performance. Together, these projects reflect a broader inquiry into how generative systems can engage with musical practices - not merely as data, but as living, evolving traditions of sound, gesture, and interaction.</p>\n<p><b>Bio</b>:\nNithya Shikarpur is a second-year PhD student at MIT advised by Prof. Cheng Zhi Anna Huang. She is interested in the modeling of human-AI interactive systems for music creation and creativity especially for low-resource genres of music. Earlier she was at Université de Montréal and Mila for her M.Sc. where she worked with Prof. Cheng-Zhi Anna Huang. She is also a practitioner and performer of Hindustani classical vocal music and draws on this knowledge to further her research projects.</p>","frontmatter":{"title":"C4DM Seminar: Nithya Shikarpur","date":"Wednesday, 22 October 2025","author":"Yinghao Ma","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png","srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/f4be1/placeholder.png 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/b444b/placeholder.png 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png 1200w","sizes":"(min-width: 1200px) 1200px, 100vw"},"sources":[{"srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/9b21f/placeholder.webp 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/9ff6b/placeholder.webp 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/f2559/placeholder.webp 1200w","type":"image/webp","sizes":"(min-width: 1200px) 1200px, 100vw"}]},"width":1200,"height":800}}}}}},"pageContext":{"slug":"/news/2025-10-22.C4DM-Seminar_Nithya_Shikarpur","breadcrumb":{"location":"/news/2025-10-22.C4DM-Seminar_Nithya_Shikarpur/","crumbs":[{"pathname":"/","crumbLabel":"Home"},{"pathname":"/news","crumbLabel":"news"},{"pathname":"/news/2025-10-22.C4DM-Seminar_Nithya_Shikarpur","crumbLabel":"2025-10-22.C4DM-Seminar_Nithya_Shikarpur"}]}}},"staticQueryHashes":["537410583"],"slicesMap":{}}