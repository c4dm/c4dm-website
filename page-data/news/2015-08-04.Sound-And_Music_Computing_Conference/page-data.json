{"componentChunkName":"component---src-templates-news-post-js","path":"/news/2015-08-04.Sound-And_Music_Computing_Conference/","result":{"data":{"markdownRemark":{"html":"<p><a href=\"http://www.maynoothuniversity.ie/smc15/\">Sound and Music Computing Conference</a> in Maynooth, Ireland saw a range of work presented by C4DM.\nThe summerschool saw workshops and discussion on Foley, Synthesis, parallel programming for audio and FPGA Technology. This included working with the Foley Artists for HBOs series \"Game of Thrones\" and constructing a Guitar Fuzz Pedal with <a href=\"http://www.maker.ie\">Maker.ie</a>.</p>\n<p>The Conference itself started with a thorough background of sound synthesis and physical modelling as a keynote from <a href=\"http://www.acoustics.ed.ac.uk/group-members/dr-stefan-bilbao/\">Stefan Bilbao</a>, from Edinburgh University. Further highlights from the first day include a <a href=\"https://staff.aist.go.jp/jun.kato/CrossSong/\">Music Puzzle Game</a> by Jordan Smith, Augmented Guitars by Otso Lähdeoja, and applications of source separation presented by Katsutoshi Itoyama from Kyoto University, Japan.</p>\n<p>Friday began with a keynote by <a href=\"http://nimbus.cit.ie/author/derry/\">Derry Fitzgerald</a> from Cork Institute of Technology, who discussed the state of the art in source separation and its applications in real world record production, including upmixing of Beachboys tracks. Following this topics such as: implementing audio plugins in Web Audio was presented by Jari Kleimola and Oliver Larkin, Predicting Rhythm with Neural Networks, by Andrew J. Lambert, and applications of Genetic Algorithms within musical composition by Róisín Loughran.</p>\n<p>Saturday started with a Keynote from Canadian composer <a href=\"http://www.sfu.ca/~truax\">Barry Truax</a> who gave an overview of his composition techniques and aesthetic ideas by referring to his extensive online archive. Presentations on MIR, perception and performance analysis were then presented, including Alex Wilson's analysis of how mixing engineers move around the mix space and Timbral Control of Granular Synthesis by Diemo Schwarz.</p>\n<p>The C4DM related papers presented were:</p>\n<p>\"SynPy: a Python Toolkit for Syncopation Modelling\" by Chunyang Song, Marcus Pearce and Christopher Harte</p>\n<p>\"Web Audio Evaluation Tool: A Browser-Based Listening Test Environment\" by Nicholas Jillings, Brecht De Man, David Moffat and Josh D. Reiss</p>\n<p>\"How Well Can a Music Emotion Recognition System Predict the Emotional Responses of Participants?\" by Yading Song and Simon Dixon</p>\n<p>\"Harmony of the Spheres: A Physics-Based Android Synthesizer and Controller with Gestural Objects and Physical Transformations\" by Florian Thalmann</p>\n<p>ex C4DM member Jordan Smith presented his latest work on\n\"CrossSong Puzzle: Generating and Unscrambling Music Mashups with Real-time Interactivity\" by Jordan B. L. Smith, Graham Percival, Jun Kato, Masataka Goto and Satoru Fukayama\nthis puzzle game can be played online at <a href=\"https://staff.aist.go.jp/jun.kato/CrossSong/\">https://staff.aist.go.jp/jun.kato/CrossSong/</a></p>\n<p>and ex C4DM Visitor Jose Valero-Mas presented work on\n\"Analyzing the influence of pitch quantization and note segmentation on singing voice alignment in the context of audio-based Query-by-Humming\" by Jose J. Valero-Mas, Justin Salamon and Emilia Gómez</p>\n<p>The full program can be found <a href=\"http://www.maynoothuniversity.ie/smc15/program.html\">here</a> and will be avalible for open access in due course.</p>\n<p>Author: Dave Moffat and Florian Thalmann.</p>","frontmatter":{"title":"C4DM attends Sound and Music Computing Conference.","date":"Tuesday, 4 August 2015","author":"Admin","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png","srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/f4be1/placeholder.png 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/b444b/placeholder.png 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png 1200w","sizes":"(min-width: 1200px) 1200px, 100vw"},"sources":[{"srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/9b21f/placeholder.webp 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/9ff6b/placeholder.webp 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/f2559/placeholder.webp 1200w","type":"image/webp","sizes":"(min-width: 1200px) 1200px, 100vw"}]},"width":1200,"height":800}}}}}},"pageContext":{"slug":"/news/2015-08-04.Sound-And_Music_Computing_Conference","breadcrumb":{"location":"/news/2015-08-04.Sound-And_Music_Computing_Conference/","crumbs":[{"pathname":"/","crumbLabel":"Home"},{"pathname":"/news","crumbLabel":"news"},{"pathname":"/news/2015-08-04.Sound-And_Music_Computing_Conference","crumbLabel":"2015-08-04.Sound-And_Music_Computing_Conference"}]}}},"staticQueryHashes":["537410583"],"slicesMap":{}}