{"componentChunkName":"component---src-templates-news-post-js","path":"/news/2024-25-09.C4DM-Seminar_Kavya_Ranjan_Saxena/","result":{"data":{"markdownRemark":{"html":"<h3>C4DM Seminar: Kavya Ranjan Saxena: Meta-learning-based domain adaptation for melody extraction</h3>\n<hr>\n<h4>QMUL, School of Electronic Engineering and Computer Science</h4>\n<h4>Centre for Digital Music Seminar Series</h4>\n<p><strong>Seminar by:</strong><br>\nKavya Ranjan Saxena</p>\n<p><strong>Date/time:  Wednesday, 25th September 2024, 11am</strong></p>\n<p>**Location: GC205, Graduate Centre Building, Mile End Campus, QMUL, E1 4NS **\nZoom: <a href=\"https://qmul-ac-uk.zoom.us/j/2387202947\">https://qmul-ac-uk.zoom.us/j/2387202947</a></p>\n<h2><b>Title</b>: Meta-learning-based domain adaptation for melody extraction</h2>\n<p><b>Abstract</b>: The task of extracting the dominant pitch from polyphonic audio is crucial in the music information retrieval field. A substantial amount of labelled audio data is required to effectively train the machine learning models to perform the task. Generally, the traditional models trained on audios of one domain, i.e., source, may not accurately extract pitch from audios of different domains, i.e., target. To boost the performance, the models are adapted on minimal labelled data from the target domain, a method known as the supervised domain adaptation. We use the meta-learning algorithm as the supervised domain adaptation method for the task of melody extraction, by proposing a novel weighting technique to handle the class imbalance when adapting to a few audios in the target domain. Further, this method can be extended as an efficient interactive melody extraction method based on active adaptation. This method selects the regions in the target audio that require human annotation using a confidence criterion based on normalized true class probability. The annotations are used by the model to adapt itself to the target domain using meta-learning. The meta-learning-based domain adaptation method is model-agnostic and can be applied to other non-adaptive melody extraction models to boost their performance.</p>\n<p><b>Bio</b>: Kavya Ranjan Saxena is a Ph.D. student at the Indian Institute of Technology Kanpur, India. Her research interests are in machine learning for signal processing with a focus on domain adaptation for melody extraction in the field of music information retrieval. Currently, she is working as an Intern â€“ Speech Research Scientist at Krutrim (an Ola company), where her work focuses on Audio LLMs.</p>","frontmatter":{"title":"C4DM Seminar:  Kavya Ranjan Saxena","date":"Wednesday, 25 September 2024","author":"Admin","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png","srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/f4be1/placeholder.png 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/b444b/placeholder.png 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png 1200w","sizes":"(min-width: 1200px) 1200px, 100vw"},"sources":[{"srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/9b21f/placeholder.webp 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/9ff6b/placeholder.webp 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/f2559/placeholder.webp 1200w","type":"image/webp","sizes":"(min-width: 1200px) 1200px, 100vw"}]},"width":1200,"height":800}}}}}},"pageContext":{"slug":"/news/2024-25-09.C4DM-Seminar_Kavya_Ranjan_Saxena","breadcrumb":{"location":"/news/2024-25-09.C4DM-Seminar_Kavya_Ranjan_Saxena/","crumbs":[{"pathname":"/","crumbLabel":"Home"},{"pathname":"/news","crumbLabel":"news"},{"pathname":"/news/2024-25-09.C4DM-Seminar_Kavya_Ranjan_Saxena","crumbLabel":"2024-25-09.C4DM-Seminar_Kavya_Ranjan_Saxena"}]}}},"staticQueryHashes":["537410583"],"slicesMap":{}}