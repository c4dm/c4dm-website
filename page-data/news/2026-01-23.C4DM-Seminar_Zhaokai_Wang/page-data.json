{"componentChunkName":"component---src-templates-news-post-js","path":"/news/2026-01-23.C4DM-Seminar_Zhaokai_Wang/","result":{"data":{"markdownRemark":{"html":"<h3>C4DM Seminar: Zhaokai Wang: From Frames to Beats: Progress and Challenges in Video-to-Music Generation</h3>\n<hr>\n<h4>QMUL, School of Electronic Engineering and Computer Science</h4>\n<h4>Centre for Digital Music Seminar Series</h4>\n<p><strong>Seminar by:</strong> Zhaokai Wang</p>\n<p><strong>Date/time:</strong>  Friday, 23th Jan 2026, 2 pm</p>\n<p><strong>Location:</strong> GC222, Graduate Centre, Mile End Campus, Queen Mary University of London</p>\n<p><a href=\"https://teams.microsoft.com/meet/31621308413281?p=6sx4w8YfWTXD9d2Gfo\">Teams meeting link</a></p>\n<h2><b>Title</b>: From Frames to Beats: Progress and Challenges in Video-to-Music Generation</h2>\n<p><b>Abstract</b>:\nVideo-to-music generation aims to create original music that is semantically, rhythmically, and emotionally aligned with the content of a given video, addressing a critical need in media creation, entertainment, and content production. This talk provides an overview of the video-to-music generation field, including a comprehensive list of models, datasets and evaluation metrics. We will share our team's research journey in this domain, spanning early symbolic music generation with handcrafted rule-based systems to the recent MLLM-driven audio synthesis approaches. We will also discuss the current challenges and impacts on the music industry, with potential future directions for advancing video-to-music generation toward more practical, creative, and human-centric applications.</p>\n<p><b>Bio</b>:\nZhaokai Wang is currently a Ph.D. student at Shanghai Jiao Tong University and Shanghai AI Laboratory, supervised by Prof. Jifeng Dai. He is currently a visiting student at UCL, supervised by Prof. Jun Wang. He obtained his bachelorâ€™s degree from Beihang University. His research interest includes multimodal large language models and music generation. He has published 10+ papers in TPAMI, NeurIPS, CVPR, ISMIR, etc, and has won the Best Paper Award in ACM MM 2021 and Best Paper Runner Up in NeurIPS 2025.\n<a href=\"https://scholar.google.com/citations?hl=zh-CN&#x26;user=W0zVf-oAAAAJ&#x26;view_op=list_works&#x26;sortby=pubdate\">https://scholar.google.com/citations?hl=zh-CN&#x26;user=W0zVf-oAAAAJ&#x26;view_op=list_works&#x26;sortby=pubdate</a></p>","frontmatter":{"title":"C4DM Seminar: Zhaokai Wang","date":"Friday, 23 January 2026","author":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png","srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/f4be1/placeholder.png 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/b444b/placeholder.png 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png 1200w","sizes":"(min-width: 1200px) 1200px, 100vw"},"sources":[{"srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/9b21f/placeholder.webp 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/9ff6b/placeholder.webp 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/f2559/placeholder.webp 1200w","type":"image/webp","sizes":"(min-width: 1200px) 1200px, 100vw"}]},"width":1200,"height":800}}}}}},"pageContext":{"slug":"/news/2026-01-23.C4DM-Seminar_Zhaokai_Wang","breadcrumb":{"location":"/news/2026-01-23.C4DM-Seminar_Zhaokai_Wang/","crumbs":[{"pathname":"/","crumbLabel":"Home"},{"pathname":"/news","crumbLabel":"news"},{"pathname":"/news/2026-01-23.C4DM-Seminar_Zhaokai_Wang","crumbLabel":"2026-01-23.C4DM-Seminar_Zhaokai_Wang"}]}}},"staticQueryHashes":["537410583"],"slicesMap":{}}