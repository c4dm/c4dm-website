{"componentChunkName":"component---src-templates-news-post-js","path":"/news/2025-03-20.AI-that_can_hear/","result":{"data":{"markdownRemark":{"html":"<p>Researchers at the <a href=\"https://www.c4dm.eecs.qmul.ac.uk/\">Centre for Digital Music</a> have developed a novel approach that enables large language models (LLMs) to \"hear\" and \"understand\" sound.</p>\n<p>Read more at: <a href=\"https://www.qmul.ac.uk/eecs/news-and-events/news/items/eecs-phd-researcher-pioneers-ai-that-can-hear-a-breakthrough-in-multimodal-generative-ai.html\">https://www.qmul.ac.uk/eecs/news-and-events/news/items/eecs-phd-researcher-pioneers-ai-that-can-hear-a-breakthrough-in-multimodal-generative-ai.html</a></p>","frontmatter":{"title":"CMAI researchers pioneer AI that can hear: a breakthrough in multimodal generative AI","date":"Thursday, 20 March 2025","author":"Emmanouil Benetos","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/e12ebbeb6e3fd35a544f18327d7e81a3/9bcb9/APT.png","srcSet":"/static/e12ebbeb6e3fd35a544f18327d7e81a3/1b3df/APT.png 1063w,\n/static/e12ebbeb6e3fd35a544f18327d7e81a3/01ddb/APT.png 2126w,\n/static/e12ebbeb6e3fd35a544f18327d7e81a3/9bcb9/APT.png 4252w","sizes":"(min-width: 4252px) 4252px, 100vw"},"sources":[{"srcSet":"/static/e12ebbeb6e3fd35a544f18327d7e81a3/40509/APT.webp 1063w,\n/static/e12ebbeb6e3fd35a544f18327d7e81a3/377e3/APT.webp 2126w,\n/static/e12ebbeb6e3fd35a544f18327d7e81a3/c6e96/APT.webp 4252w","type":"image/webp","sizes":"(min-width: 4252px) 4252px, 100vw"}]},"width":4252,"height":1653.0000000000002}}}}}},"pageContext":{"slug":"/news/2025-03-20.AI-that_can_hear","breadcrumb":{"location":"/news/2025-03-20.AI-that_can_hear/","crumbs":[{"pathname":"/","crumbLabel":"Home"},{"pathname":"/news","crumbLabel":"news"},{"pathname":"/news/2025-03-20.AI-that_can_hear","crumbLabel":"2025-03-20.AI-that_can_hear"}]}}},"staticQueryHashes":["537410583"],"slicesMap":{}}