{"componentChunkName":"component---src-templates-news-post-js","path":"/news/2017-07-17.C4DM-Seminar_-_Ching_Wei_Chen_and_Andreas_Jansson/","result":{"data":{"markdownRemark":{"html":"<p>For external participants: Please join our mailing list to receive announcements of future C4DM seminars: <a href=\"http://c4dm.eecs.qmul.ac.uk/seminars.html\">http://c4dm.eecs.qmul.ac.uk/seminars.html</a></p>\n<p><span style=\"font-size: 130%;\">Date and Time</span></br>\nMonday, 17th July 2017, at 4:00pm</p>\n<p><span style=\"font-size: 130%;\">Place</span></br>\nMost rooms are booked for graduation. Therefore, the talk will be in:</br></p>\n<p>Room Law 1.00, Laws Building, Queen Mary University of London, Mile End Road, London E1 4NS. Information on how to access the school can be found at <a href=\"http://www.eecs.qmul.ac.uk/contact-us/\"><a href=\"http://www.eecs.qmul.ac.uk/contact-us/\">http://www.eecs.qmul.ac.uk/contact-us/</a></a>.</p>\n<p><span style=\"font-size: 130%;\">Speaker</span></br>\nChing-Wei Chen and Andreas Jansson</p>\n<p><span style=\"font-size: 130%;\">Abstract</span></br>\nChing-Wei will begin the talk with an introduction of Spotify's music personalization features, such as Discover Weekly and Release Radar, with a brief mention of some Machine Learning and Audio Analysis technologies being used behind the scenes. Andreas will then continue with a presentation of his recent work in vocal separation:</p>\n<p>The decomposition of a music audio signal into its vocal and backing track components is analogous to image-to-image translation, where a mixed spectrogram is trans-formed into its constituent sources. We propose a novel application of the U-Net architecture — initially developed for medical imaging — for the task of source separation, given its proven capacity for recreating the fine, low-level detail required for high-quality audio reproduction. The model is trained on a large set of data automatically derived from the Spotify commercial music catalogue.</p>\n<p><span style=\"font-size: 130%;\">Bio</span></br>\nChing-Wei is a Chapter Lead for Machine Learning at Spotify in NYC, where members of his team work on music recommendation and analysis. Previously he was at SoundCloud managing their Content ID/Copyright team, and before that at Gracenote where he researched musical mood and tempo classification.</p>\n<p>Andreas works as an engineer / researcher in the music understanding group at Spotify in NYC. Before that he was a developer at The Echo Nest in Boston and This Is My Jam in London. He's also a part-time PhD student at City University, supervised by Tillman Weyde.</p>","frontmatter":{"title":"C4DM Seminar: Ching-Wei Chen and Andreas Jansson","date":"Monday, 17 July 2017","author":"Admin","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png","srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/f4be1/placeholder.png 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/b444b/placeholder.png 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png 1200w","sizes":"(min-width: 1200px) 1200px, 100vw"},"sources":[{"srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/9b21f/placeholder.webp 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/9ff6b/placeholder.webp 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/f2559/placeholder.webp 1200w","type":"image/webp","sizes":"(min-width: 1200px) 1200px, 100vw"}]},"width":1200,"height":800}}}}}},"pageContext":{"slug":"/news/2017-07-17.C4DM-Seminar_-_Ching_Wei_Chen_and_Andreas_Jansson","breadcrumb":{"location":"/news/2017-07-17.C4DM-Seminar_-_Ching_Wei_Chen_and_Andreas_Jansson/","crumbs":[{"pathname":"/","crumbLabel":"Home"},{"pathname":"/news","crumbLabel":"news"},{"pathname":"/news/2017-07-17.C4DM-Seminar_-_Ching_Wei_Chen_and_Andreas_Jansson","crumbLabel":"2017-07-17.C4DM-Seminar_-_Ching_Wei_Chen_and_Andreas_Jansson"}]}}},"staticQueryHashes":["537410583"],"slicesMap":{}}