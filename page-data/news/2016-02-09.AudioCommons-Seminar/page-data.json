{"componentChunkName":"component---src-templates-news-post-js","path":"/news/2016-02-09.AudioCommons-Seminar/","result":{"data":{"markdownRemark":{"html":"<p>On Tuesday, 9th February 2016, at 11:00am, Xavier Serra and Frederic Font will give a seminar about our joint H2020 funded project Audio Commons.</p>\n<p>The talk will take place in the ITL Top Floor Meeting room.</p>\n<p>Audio Commons is about technologies to facilitate the reuse of CC licensed audio content on the Web in applications such as music production, sound design, gaming, sound branding etc.. and will welcome a number of new C4DM members over the coming weeks. Please come along to the talk if you'd like to hear more about Audio Commons and in particular, the consortium's plan to create an initiative around sharing audio that will last beyond the 3 years of project funding.</p>\n<p>Title:\n“The AudioCommons Initiative and the technologies for facilitating the reuse of open audio content\"</p>\n<p>Presenters:\nXavier Serra and Frederic Font, Music Technology Group, Universitat Pompeu Fabra, Barcelona (<a href=\"http://mtg.upf.edu/\">http://mtg.upf.edu/</a>)</p>\n<p>Abstract:\nSignificant amounts of user-generated audio content, such as sound effects, musical samples and music pieces, are uploaded to online repositories and made available under open licenses. Moreover, a constantly increasing amount of multimedia content, originally released with traditional licenses, is  becoming public domain as its license expires. Nevertheless, this content is not much used in professional productions. There is still a lack of familiarity and understanding of the legal context of all this open content, but there are also problems related with its accessibility. A big percentage of this content remains unreachable either because is not published online or because it is not well organised and annotated. With the Audio Commons Initiative we want to promote the use of open audio content and to develop technologies with which to support the ecosystem composed by content repositories, production tools and users. These technologies should enable the reuse of this audio material, facilitating its integration in the production workflows used by the creative industries. In this workshop we will go over the core ideas behind this initiative, then overview the existing audio repositories, technologies and production tools related to it, and finally outline the planned tasks to address the challenges posed by the initiative. More information on the Audio Commons Initiative:  <a href=\"http://www.audiocommons.org/\">http://www.audiocommons.org/</a></p>\n<p>The AudioCommons consortium is formed by leading research institutes in sound and music computing and key players in the creative industries. Academic partners include the Music Technology Group from Universitat Pompeu Fabra (MTG, project coordinator), the Centre for Digital Music from Queen Mary University of London (C4DM), and three research groups from University of Surrey: the Centre for Vision, Speech and Signal Processing (CVSSP), the Institute of Sound Recording (IoSR) and the Centre for the Digital Economy (CoDE). On the industry side, the AudioCommons consortium includes Jamendo (one of the biggest platforms for sharing independent Creative Commons music), AudioGaming (an innovative company developing next generation audio tools for sound designers and video game developers), and Waves (world’s leading developer of audio DSP solutions for the professional, broadcast, and consumer electronics audio markets).</p>\n<p>Bios:\nXavier Serra is Associate Professor of the Department of Information and Communication Technologies and Director of the Music Technology Group at the Universitat Pompeu Fabra in Barcelona. After a multidisciplinary academic education he obtained a PhD in Computer Music from Stanford University in 1989 with a dissertation on the spectral processing of musical sounds that is considered a key reference in the field. His research interests cover the analysis, description and synthesis of sound and music signals, with a balance between basic and applied research and approaches from both scientific/technological and humanistic/artistic disciplines. Dr. Serra is very active in promoting initiatives in the field of Sound and Music Computing at the local and international levels, being involved in the editorial board of a number of journals and conferences and giving lectures on current and future challenges of the field. He has recently been awarded an Advanced Grant of the European Research Council to carry out the project CompMusic aimed at promoting multicultural approaches in music computing research.  Xavier Serra is the PI of the AudioCommons project.</p>\n<p>Frederic Font is a post-doc researcher at the Music Technology Group of the Department of Information and Communication Technologies (Universitat Pompeu Fabra, Barcelona). Frederic Font holds a degree in Telecommunications Engineering from Universitat Politècnica de Catalunya (2007) and a MSc in Sound and Music Computing from Universitat Pompeu Fabra (2010). In 2015, he obtained a PhD in Sound and Music Computing from Universitat Pompeu Fabra. His research interests lay in the field of sound and music computing, audio processing and the semantic representation of audio content, motivated by the creative potential that online communities of users have through online sound sharing sites such as Freesound. His current research is focused on how to properly describe audio content in order to improve its accessibility and future reuse in musically creative contexts. This includes the use of a wide range of techniques from signal processing and machine learning to semantic representation of music information and analysis of user communities and their generated metadata. Frederic Font is also the lead developer and maintainer of Freesound and the Freesound API.</p>","frontmatter":{"title":"Audio Commons Seminar - Xavier Serra and Frederic Font","date":"Tuesday, 9 February 2016","author":"Admin","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png","srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/f4be1/placeholder.png 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/b444b/placeholder.png 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/ba986/placeholder.png 1200w","sizes":"(min-width: 1200px) 1200px, 100vw"},"sources":[{"srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/9b21f/placeholder.webp 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/9ff6b/placeholder.webp 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/f2559/placeholder.webp 1200w","type":"image/webp","sizes":"(min-width: 1200px) 1200px, 100vw"}]},"width":1200,"height":800}}}}}},"pageContext":{"slug":"/news/2016-02-09.AudioCommons-Seminar","breadcrumb":{"location":"/news/2016-02-09.AudioCommons-Seminar/","crumbs":[{"pathname":"/","crumbLabel":"Home"},{"pathname":"/news","crumbLabel":"news"},{"pathname":"/news/2016-02-09.AudioCommons-Seminar","crumbLabel":"2016-02-09.AudioCommons-Seminar"}]}}},"staticQueryHashes":["537410583"],"slicesMap":{}}