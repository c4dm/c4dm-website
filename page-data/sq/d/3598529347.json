{"data":{"text":{"html":"","frontmatter":{"title":""}},"people":{"nodes":[{"id":"5dd23ff3-3112-5b88-8b4e-f6493bdcdbac","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#8898c8","images":{"fallback":{"src":"/static/bf8d7356ac6d442350ba1cb9bcc35445/baaed/andrewmcpherson.jpg","srcSet":"/static/bf8d7356ac6d442350ba1cb9bcc35445/dd515/andrewmcpherson.jpg 200w,\n/static/bf8d7356ac6d442350ba1cb9bcc35445/47930/andrewmcpherson.jpg 400w,\n/static/bf8d7356ac6d442350ba1cb9bcc35445/baaed/andrewmcpherson.jpg 800w","sizes":"(min-width: 800px) 800px, 100vw"},"sources":[{"srcSet":"/static/bf8d7356ac6d442350ba1cb9bcc35445/2e34e/andrewmcpherson.webp 200w,\n/static/bf8d7356ac6d442350ba1cb9bcc35445/416c3/andrewmcpherson.webp 400w,\n/static/bf8d7356ac6d442350ba1cb9bcc35445/c1587/andrewmcpherson.webp 800w","type":"image/webp","sizes":"(min-width: 800px) 800px, 100vw"}]},"width":800,"height":800}}},"name":"Prof Andrew McPherson","role":"Academic","url":"http://www.eecs.qmul.ac.uk/~andrewm","acadposition":"Professor of Musical Interaction","blurb":"new interfaces for musical expression, augmented instruments, performance study, human-computer interaction, embedded hardware","themes":["augmi","soundsynthesis"]}},{"id":"7920f116-7143-57a4-b40b-9325b220e835","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/static/122d04ac0e0cbe928b1e890f48016415/2e67f/benjaminhayes.jpg","srcSet":"/static/122d04ac0e0cbe928b1e890f48016415/2b6e2/benjaminhayes.jpg 73w,\n/static/122d04ac0e0cbe928b1e890f48016415/ca0c2/benjaminhayes.jpg 147w,\n/static/122d04ac0e0cbe928b1e890f48016415/2e67f/benjaminhayes.jpg 293w","sizes":"(min-width: 293px) 293px, 100vw"},"sources":[{"srcSet":"/static/122d04ac0e0cbe928b1e890f48016415/96ea5/benjaminhayes.webp 73w,\n/static/122d04ac0e0cbe928b1e890f48016415/93d5d/benjaminhayes.webp 147w,\n/static/122d04ac0e0cbe928b1e890f48016415/4cb57/benjaminhayes.webp 293w","type":"image/webp","sizes":"(min-width: 293px) 293px, 100vw"}]},"width":293,"height":293}}},"name":"Benjamin Hayes","role":"PhD","url":"http://eecs.qmul.ac.uk/profiles/hayesbenjaminjames.html","acadposition":"PhD Student","blurb":"Perceptually motivated deep learning approaches to creative sound synthesis","themes":["soundsynthesis","mcog"]}},{"id":"3e2bbfc8-0f9b-5aac-ba55-b0f8ffc899b9","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#282828","images":{"fallback":{"src":"/static/92ff73f501424e00ed9ec016481170c9/7706b/berkerbanar.jpg","srcSet":"/static/92ff73f501424e00ed9ec016481170c9/96deb/berkerbanar.jpg 150w,\n/static/92ff73f501424e00ed9ec016481170c9/ed539/berkerbanar.jpg 301w,\n/static/92ff73f501424e00ed9ec016481170c9/7706b/berkerbanar.jpg 601w","sizes":"(min-width: 601px) 601px, 100vw"},"sources":[{"srcSet":"/static/92ff73f501424e00ed9ec016481170c9/c65bc/berkerbanar.webp 150w,\n/static/92ff73f501424e00ed9ec016481170c9/214a8/berkerbanar.webp 301w,\n/static/92ff73f501424e00ed9ec016481170c9/2b014/berkerbanar.webp 601w","type":"image/webp","sizes":"(min-width: 601px) 601px, 100vw"}]},"width":601,"height":601}}},"name":"Berker Banar","role":"PhD","url":"http://eecs.qmul.ac.uk/profiles/banarberker.html","acadposition":"PhD Student","blurb":"Towards Composing Contemporary Classical Music using Generative Deep Learning","themes":["mir","soundsynthesis"]}},{"id":"000ae1c5-cd99-587f-b370-d863b89be317","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#e8e8e8","images":{"fallback":{"src":"/static/4d90e16ad97b57932e1d33039b1d87cc/6d0f2/carlosdelavegamartin.jpg","srcSet":"/static/4d90e16ad97b57932e1d33039b1d87cc/f7afd/carlosdelavegamartin.jpg 496w,\n/static/4d90e16ad97b57932e1d33039b1d87cc/09746/carlosdelavegamartin.jpg 991w,\n/static/4d90e16ad97b57932e1d33039b1d87cc/6d0f2/carlosdelavegamartin.jpg 1982w","sizes":"(min-width: 1982px) 1982px, 100vw"},"sources":[{"srcSet":"/static/4d90e16ad97b57932e1d33039b1d87cc/45827/carlosdelavegamartin.webp 496w,\n/static/4d90e16ad97b57932e1d33039b1d87cc/81db5/carlosdelavegamartin.webp 991w,\n/static/4d90e16ad97b57932e1d33039b1d87cc/94e91/carlosdelavegamartin.webp 1982w","type":"image/webp","sizes":"(min-width: 1982px) 1982px, 100vw"}]},"width":1982,"height":1982}}},"name":"Carlos De La Vega Martin","role":"PhD","url":"https://www.qmul.ac.uk/eecs/people/profiles/delavegamartincarlos.html","acadposition":"PhD Student","blurb":"Neural Drum Synthesis","themes":["soundsynthesis"]}},{"id":"34ef929b-de59-5c95-a554-597f98d80226","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/83b515844814d95b7fc7d641a74fed63/9cf6c/chinyunyu.jpg","srcSet":"/static/83b515844814d95b7fc7d641a74fed63/2f83b/chinyunyu.jpg 351w,\n/static/83b515844814d95b7fc7d641a74fed63/b41ee/chinyunyu.jpg 702w,\n/static/83b515844814d95b7fc7d641a74fed63/9cf6c/chinyunyu.jpg 1403w","sizes":"(min-width: 1403px) 1403px, 100vw"},"sources":[{"srcSet":"/static/83b515844814d95b7fc7d641a74fed63/9bbac/chinyunyu.webp 351w,\n/static/83b515844814d95b7fc7d641a74fed63/ce9fc/chinyunyu.webp 702w,\n/static/83b515844814d95b7fc7d641a74fed63/f5914/chinyunyu.webp 1403w","type":"image/webp","sizes":"(min-width: 1403px) 1403px, 100vw"}]},"width":1403,"height":1403}}},"name":"Chin-Yun Yu","role":"PhD","url":"https://yoyololicon.github.io/","acadposition":"PhD Student","blurb":"Neural Audio Synthesis with Expressiveness Control","themes":["audioeng","mir","soundsynthesis"]}},{"id":"612a6483-8966-5db8-9744-f6fd1021a11a","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#987878","images":{"fallback":{"src":"/static/1811de1c418db6a7f0c4a8727b254b42/6fd26/davidsudholt.png","srcSet":"/static/1811de1c418db6a7f0c4a8727b254b42/b5a32/davidsudholt.png 78w,\n/static/1811de1c418db6a7f0c4a8727b254b42/d8a72/davidsudholt.png 156w,\n/static/1811de1c418db6a7f0c4a8727b254b42/6fd26/davidsudholt.png 312w","sizes":"(min-width: 312px) 312px, 100vw"},"sources":[{"srcSet":"/static/1811de1c418db6a7f0c4a8727b254b42/7a63e/davidsudholt.webp 78w,\n/static/1811de1c418db6a7f0c4a8727b254b42/d1e3d/davidsudholt.webp 156w,\n/static/1811de1c418db6a7f0c4a8727b254b42/da295/davidsudholt.webp 312w","type":"image/webp","sizes":"(min-width: 312px) 312px, 100vw"}]},"width":312,"height":312}}},"name":"David SÃ¼dholt","role":"PhD","url":"https://dsuedholt.github.io/","acadposition":"PhD Student","blurb":"Machine Learning of Physical Models for Voice Synthesis","themes":["soundsynthesis","audioeng"]}},{"id":"2b006670-df63-567c-9c51-62d19c6b1372","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#081808","images":{"fallback":{"src":"/static/38f5515ab7b3aa20eeef7b22fd3a5581/0e51d/eleanorrow.jpg","srcSet":"/static/38f5515ab7b3aa20eeef7b22fd3a5581/2c33f/eleanorrow.jpg 56w,\n/static/38f5515ab7b3aa20eeef7b22fd3a5581/f41fb/eleanorrow.jpg 112w,\n/static/38f5515ab7b3aa20eeef7b22fd3a5581/0e51d/eleanorrow.jpg 224w","sizes":"(min-width: 224px) 224px, 100vw"},"sources":[{"srcSet":"/static/38f5515ab7b3aa20eeef7b22fd3a5581/f8744/eleanorrow.webp 56w,\n/static/38f5515ab7b3aa20eeef7b22fd3a5581/65bf6/eleanorrow.webp 112w,\n/static/38f5515ab7b3aa20eeef7b22fd3a5581/f42a0/eleanorrow.webp 224w","type":"image/webp","sizes":"(min-width: 224px) 224px, 100vw"}]},"width":224,"height":224}}},"name":"Eleanor Row","role":"PhD","url":"http://eecs.qmul.ac.uk/profiles/roweleanorroxannevictoria.html","acadposition":"PhD Student","blurb":"Automatic micro-composition for professional/novice composers using generative models as creativity support tools","themes":["soundsynthesis"]}},{"id":"961a0884-4935-5955-bb6a-176115804b95","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#e8e8d8","images":{"fallback":{"src":"/static/b57035b0802024ae7531105179b51594/3fd2e/jacksonloth.jpg","srcSet":"/static/b57035b0802024ae7531105179b51594/4a00f/jacksonloth.jpg 756w,\n/static/b57035b0802024ae7531105179b51594/facf2/jacksonloth.jpg 1512w,\n/static/b57035b0802024ae7531105179b51594/3fd2e/jacksonloth.jpg 3024w","sizes":"(min-width: 3024px) 3024px, 100vw"},"sources":[{"srcSet":"/static/b57035b0802024ae7531105179b51594/0531b/jacksonloth.webp 756w,\n/static/b57035b0802024ae7531105179b51594/dd848/jacksonloth.webp 1512w,\n/static/b57035b0802024ae7531105179b51594/95aac/jacksonloth.webp 3024w","type":"image/webp","sizes":"(min-width: 3024px) 3024px, 100vw"}]},"width":3024,"height":3024}}},"name":"Jackson Loth","role":"PhD","url":"https://www.qmul.ac.uk/eecs/people/profiles/lothjacksonjames.html","acadposition":"PhD Student","blurb":"Time to vibe together: cloud-based guitar and intelligent agent","themes":["augmi","soundsynthesis"]}},{"id":"ca2575a9-c402-50c9-a660-eea9648428a6","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#b8d8f8","images":{"fallback":{"src":"/static/e3f990a7d5022b64b25e5c46e4a6d5bf/47930/joshuadreiss.jpg","srcSet":"/static/e3f990a7d5022b64b25e5c46e4a6d5bf/e07e1/joshuadreiss.jpg 100w,\n/static/e3f990a7d5022b64b25e5c46e4a6d5bf/dd515/joshuadreiss.jpg 200w,\n/static/e3f990a7d5022b64b25e5c46e4a6d5bf/47930/joshuadreiss.jpg 400w","sizes":"(min-width: 400px) 400px, 100vw"},"sources":[{"srcSet":"/static/e3f990a7d5022b64b25e5c46e4a6d5bf/d8057/joshuadreiss.webp 100w,\n/static/e3f990a7d5022b64b25e5c46e4a6d5bf/2e34e/joshuadreiss.webp 200w,\n/static/e3f990a7d5022b64b25e5c46e4a6d5bf/416c3/joshuadreiss.webp 400w","type":"image/webp","sizes":"(min-width: 400px) 400px, 100vw"}]},"width":400,"height":400}}},"name":"Prof Joshua D Reiss","role":"Academic","url":"http://www.eecs.qmul.ac.uk/~josh/","acadposition":"Professor of Audio Engineering","blurb":"sound engineering, intelligent audio production, sound synthesis, audio effects, automatic mixing","themes":["audioeng","soundsynthesis"]}},{"id":"96844f85-b589-5907-be07-6cc39213f206","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/51634a254670aa2e07b701a172ad9361/8f4a8/marcocomunita.jpg","srcSet":"/static/51634a254670aa2e07b701a172ad9361/82155/marcocomunita.jpg 107w,\n/static/51634a254670aa2e07b701a172ad9361/61790/marcocomunita.jpg 214w,\n/static/51634a254670aa2e07b701a172ad9361/8f4a8/marcocomunita.jpg 428w","sizes":"(min-width: 428px) 428px, 100vw"},"sources":[{"srcSet":"/static/51634a254670aa2e07b701a172ad9361/d9648/marcocomunita.webp 107w,\n/static/51634a254670aa2e07b701a172ad9361/f6ee1/marcocomunita.webp 214w,\n/static/51634a254670aa2e07b701a172ad9361/4ec0e/marcocomunita.webp 428w","type":"image/webp","sizes":"(min-width: 428px) 428px, 100vw"}]},"width":428,"height":428}}},"name":"Marco ComunitÃ ","role":"PhD","url":"http://eecs.qmul.ac.uk/profiles/comunitamarco.html","acadposition":"PhD Student","blurb":"Machine learning applied to sound synthesis models","themes":["audioeng","soundsynthesis"]}},{"id":"de8a6a9d-d9db-5d6f-aa49-d6383eab8ec3","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#d8c8c8","images":{"fallback":{"src":"/static/525d06e75294a7bf61d839700b1d2be5/3c342/ningzhiwang.jpg","srcSet":"/static/525d06e75294a7bf61d839700b1d2be5/19f6e/ningzhiwang.jpg 106w,\n/static/525d06e75294a7bf61d839700b1d2be5/a8230/ningzhiwang.jpg 212w,\n/static/525d06e75294a7bf61d839700b1d2be5/3c342/ningzhiwang.jpg 423w","sizes":"(min-width: 423px) 423px, 100vw"},"sources":[{"srcSet":"/static/525d06e75294a7bf61d839700b1d2be5/7a2a0/ningzhiwang.webp 106w,\n/static/525d06e75294a7bf61d839700b1d2be5/fbd6b/ningzhiwang.webp 212w,\n/static/525d06e75294a7bf61d839700b1d2be5/fb6ab/ningzhiwang.webp 423w","type":"image/webp","sizes":"(min-width: 423px) 423px, 100vw"}]},"width":423,"height":423}}},"name":"Ningzhi Wang","role":"PhD","url":"","acadposition":"PhD Student","blurb":"Generative Models For Music Audio Representation And Understanding","themes":["mir","mcog","soundsynthesis"]}},{"id":"aec8c261-f5de-537e-8871-b725d92c8ed0","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#787878","images":{"fallback":{"src":"/static/7a140f866e4e9fa0d9f50cfd706a5f9b/a8c60/rodrigomauriciodiazfernandez.jpg","srcSet":"/static/7a140f866e4e9fa0d9f50cfd706a5f9b/67766/rodrigomauriciodiazfernandez.jpg 174w,\n/static/7a140f866e4e9fa0d9f50cfd706a5f9b/28fc8/rodrigomauriciodiazfernandez.jpg 349w,\n/static/7a140f866e4e9fa0d9f50cfd706a5f9b/a8c60/rodrigomauriciodiazfernandez.jpg 697w","sizes":"(min-width: 697px) 697px, 100vw"},"sources":[{"srcSet":"/static/7a140f866e4e9fa0d9f50cfd706a5f9b/0515f/rodrigomauriciodiazfernandez.webp 174w,\n/static/7a140f866e4e9fa0d9f50cfd706a5f9b/546d1/rodrigomauriciodiazfernandez.webp 349w,\n/static/7a140f866e4e9fa0d9f50cfd706a5f9b/dfdb2/rodrigomauriciodiazfernandez.webp 697w","type":"image/webp","sizes":"(min-width: 697px) 697px, 100vw"}]},"width":697,"height":697}}},"name":"Rodrigo Mauricio Diaz Fernandez","role":"PhD","url":"https://www.qmul.ac.uk/eecs/people/profiles/diazfernandezrodrigomauricio.html","acadposition":"PhD Student","blurb":"Hybrid Neural Methods for Sound Synthesis","themes":["audioeng","soundsynthesis"]}},{"id":"72d3c05f-c5ce-5fe9-9c95-733813b814f7","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/7194c98c40fd74305a818071553ec197/68d26/shubhrsingh.png","srcSet":"/static/7194c98c40fd74305a818071553ec197/d8a72/shubhrsingh.png 156w,\n/static/7194c98c40fd74305a818071553ec197/2e7f0/shubhrsingh.png 311w,\n/static/7194c98c40fd74305a818071553ec197/68d26/shubhrsingh.png 622w","sizes":"(min-width: 622px) 622px, 100vw"},"sources":[{"srcSet":"/static/7194c98c40fd74305a818071553ec197/d1e3d/shubhrsingh.webp 156w,\n/static/7194c98c40fd74305a818071553ec197/b699b/shubhrsingh.webp 311w,\n/static/7194c98c40fd74305a818071553ec197/3286e/shubhrsingh.webp 622w","type":"image/webp","sizes":"(min-width: 622px) 622px, 100vw"}]},"width":622,"height":622}}},"name":"Shubhr Singh","role":"PhD","url":"http://eecs.qmul.ac.uk/profiles/singhshubhr.html","acadposition":"PhD Student","blurb":"Audio Applications of Novel Mathematical Methods in Deep Learning","themes":["soundsynthesis","mlist"]}},{"id":"563606d0-e18c-52ae-a94f-124b16a4f868","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#989898","images":{"fallback":{"src":"/static/b1d39ee566fdd8e6fcb02de5fd0b11d9/ba56e/yazhouli.jpg","srcSet":"/static/b1d39ee566fdd8e6fcb02de5fd0b11d9/64c35/yazhouli.jpg 173w,\n/static/b1d39ee566fdd8e6fcb02de5fd0b11d9/605c6/yazhouli.jpg 347w,\n/static/b1d39ee566fdd8e6fcb02de5fd0b11d9/ba56e/yazhouli.jpg 693w","sizes":"(min-width: 693px) 693px, 100vw"},"sources":[{"srcSet":"/static/b1d39ee566fdd8e6fcb02de5fd0b11d9/68ba0/yazhouli.webp 173w,\n/static/b1d39ee566fdd8e6fcb02de5fd0b11d9/d5fde/yazhouli.webp 347w,\n/static/b1d39ee566fdd8e6fcb02de5fd0b11d9/7c9d1/yazhouli.webp 693w","type":"image/webp","sizes":"(min-width: 693px) 693px, 100vw"}]},"width":693,"height":693}}},"name":"Yazhou Li","role":"PhD","url":"https://www.qmul.ac.uk/eecs/people/profiles/liyazhou.html","acadposition":"PhD Student","blurb":"Virtual Placement of Objects in Acoustic Scenes","themes":["audioeng","soundsynthesis","isam","mlist"]}},{"id":"b699de08-bbee-5b10-bd93-9643604e2681","frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/89c68e42d18742a0131b975951dddd78/7eeb7/yinjyunluo.png","srcSet":"/static/89c68e42d18742a0131b975951dddd78/10479/yinjyunluo.png 115w,\n/static/89c68e42d18742a0131b975951dddd78/4437f/yinjyunluo.png 229w,\n/static/89c68e42d18742a0131b975951dddd78/7eeb7/yinjyunluo.png 458w","sizes":"(min-width: 458px) 458px, 100vw"},"sources":[{"srcSet":"/static/89c68e42d18742a0131b975951dddd78/f8466/yinjyunluo.webp 115w,\n/static/89c68e42d18742a0131b975951dddd78/4b05c/yinjyunluo.webp 229w,\n/static/89c68e42d18742a0131b975951dddd78/1efa3/yinjyunluo.webp 458w","type":"image/webp","sizes":"(min-width: 458px) 458px, 100vw"}]},"width":458,"height":458}}},"name":"Yin-Jyun Luo","role":"PhD","url":"http://eecs.qmul.ac.uk/profiles/luoyin-jyun.html","acadposition":"PhD Student","blurb":"Industry-scale Machine Listening for Music and Audio Data","themes":["soundsynthesis","mlist"]}}]}}}