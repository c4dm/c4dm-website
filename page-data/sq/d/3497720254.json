{"data":{"active":{"nodes":[{"frontmatter":{"partner":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/6499965fc9609e5e679af02f6157ecb3/6e1f6/RAE_Logo_Black_RGB.png","srcSet":"/static/6499965fc9609e5e679af02f6157ecb3/57cda/RAE_Logo_Black_RGB.png 877w,\n/static/6499965fc9609e5e679af02f6157ecb3/55510/RAE_Logo_Black_RGB.png 1754w,\n/static/6499965fc9609e5e679af02f6157ecb3/6e1f6/RAE_Logo_Black_RGB.png 3508w","sizes":"(min-width: 3508px) 3508px, 100vw"},"sources":[{"srcSet":"/static/6499965fc9609e5e679af02f6157ecb3/3dc64/RAE_Logo_Black_RGB.webp 877w,\n/static/6499965fc9609e5e679af02f6157ecb3/6e9a8/RAE_Logo_Black_RGB.webp 1754w,\n/static/6499965fc9609e5e679af02f6157ecb3/c2a1e/RAE_Logo_Black_RGB.webp 3508w","type":"image/webp","sizes":"(min-width: 3508px) 3508px, 100vw"}]},"width":3508,"height":3508}}},"title":"Bela / Royal Academy of Engineering Senior Research Fellow in Embedded Music Computing","link":"https://www.raeng.org.uk/grants-prizes/grants/support-for-research/research-chairs/current-and-recent-awards"},"id":"9cccf3cb-8962-5651-90f8-a154484a8cf3"},{"frontmatter":{"partner":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/e9ef6/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/03bfb/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/41b67/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/5e2d0/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/36fd4/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"Bridging the Gap - visually impaired and sighted music producers working side by side","link":"https://gtr.ukri.org/projects?ref=AH%2FV011340%2F1"},"id":"8da962ce-8d22-596f-8d7e-a94e2f2c32f0"},{"frontmatter":{"partner":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/e9ef6/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/03bfb/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/41b67/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/5e2d0/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/36fd4/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"Centre for Doctoral Training (CDT) in Data Centric Engineering","link":"https://gtr.ukri.org/projects?ref=EP%2FV519935%2F1"},"id":"3633aba2-92e2-5834-8037-5213c0285487"},{"frontmatter":{"partner":"DAACI Ltd","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/4cb4c02fdb1c79874502ca3652d98a68/d7adc/daaci.png","srcSet":"/static/4cb4c02fdb1c79874502ca3652d98a68/4142b/daaci.png 143w,\n/static/4cb4c02fdb1c79874502ca3652d98a68/979d1/daaci.png 285w,\n/static/4cb4c02fdb1c79874502ca3652d98a68/d7adc/daaci.png 570w","sizes":"(min-width: 570px) 570px, 100vw"},"sources":[{"srcSet":"/static/4cb4c02fdb1c79874502ca3652d98a68/79250/daaci.webp 143w,\n/static/4cb4c02fdb1c79874502ca3652d98a68/47957/daaci.webp 285w,\n/static/4cb4c02fdb1c79874502ca3652d98a68/1f845/daaci.webp 570w","type":"image/webp","sizes":"(min-width: 570px) 570px, 100vw"}]},"width":570,"height":570}}},"title":"Expressive Performance Rendering for Music Generation Systems","link":"https://www.aim.qmul.ac.uk/"},"id":"506e5fc5-b448-5632-907c-ee5b8ae34c1b"},{"frontmatter":{"partner":"BBC","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/b7ed455d7da2ce1c44fff43ee28c5c1d/7ad53/bbc.png","srcSet":"/static/b7ed455d7da2ce1c44fff43ee28c5c1d/fc686/bbc.png 1024w,\n/static/b7ed455d7da2ce1c44fff43ee28c5c1d/be023/bbc.png 2048w,\n/static/b7ed455d7da2ce1c44fff43ee28c5c1d/7ad53/bbc.png 4096w","sizes":"(min-width: 4096px) 4096px, 100vw"},"sources":[{"srcSet":"/static/b7ed455d7da2ce1c44fff43ee28c5c1d/2ae1e/bbc.webp 1024w,\n/static/b7ed455d7da2ce1c44fff43ee28c5c1d/6557e/bbc.webp 2048w,\n/static/b7ed455d7da2ce1c44fff43ee28c5c1d/8ce13/bbc.webp 4096w","type":"image/webp","sizes":"(min-width: 4096px) 4096px, 100vw"}]},"width":4096,"height":4096}}},"title":"Centre for Doctoral Training in Data-informed Audience-centric Media Engineering (DAME)","link":"https://dame.qmul.ac.uk/"},"id":"606198c9-6f72-57c9-867c-81c83e67e1ff"},{"frontmatter":{"partner":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/e9ef6/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/03bfb/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/41b67/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/5e2d0/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/36fd4/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"GraphNEx: Graph Neural Networks for Explainable Artificial Intelligence","link":"https://gtr.ukri.org/projects?ref=EP%2FV062107%2F1"},"id":"2f36a783-1442-52ad-87dd-e4743da5358a"},{"frontmatter":{"partner":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/e9ef6/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/03bfb/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/41b67/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/5e2d0/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/36fd4/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"New Directions in Digital Jazz Studies: Music Information Retrieval and AI Support for Jazz Scholarship in Digital Archives","link":"https://gtr.ukri.org/projects?ref=AH%2FV009699%2F1"},"id":"bbc3e7d8-fec5-5f93-979a-85e5305ce6dc"},{"frontmatter":{"partner":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/e9ef6/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/03bfb/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/41b67/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/5e2d0/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/36fd4/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"Designing new musical technologies for older adults' wellbeing","link":"https://gtr.ukri.org/projects?ref=MR%2FT040580%2F1"},"id":"aa4d6aa2-5969-5c1a-9a26-02c167f8c10f"},{"frontmatter":{"partner":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/e9ef6/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/03bfb/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/41b67/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/5e2d0/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/36fd4/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"UKRI Centre for Doctoral Training in Artificial Intelligence and Music (AIM)","link":"https://www.aim.qmul.ac.uk/"},"id":"5f05c42b-efc1-5e56-831c-f7fc4297bf20"},{"frontmatter":{"partner":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/e9ef6/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/03bfb/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/41b67/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/5e2d0/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/36fd4/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"Music and Disability: Deconstructing the barriers to full participation","link":"https://gtr.ukri.org/projects?ref=AH%2FW010429%2F1"},"id":"398457f7-42ec-51d3-901f-6a266040263c"},{"frontmatter":{"partner":"Ovomind SA","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/eb4749c9cfc9ecf498eb8a6b8daaf25f/5b441/ovomind.png","srcSet":"/static/eb4749c9cfc9ecf498eb8a6b8daaf25f/55715/ovomind.png 126w,\n/static/eb4749c9cfc9ecf498eb8a6b8daaf25f/f722f/ovomind.png 251w,\n/static/eb4749c9cfc9ecf498eb8a6b8daaf25f/5b441/ovomind.png 502w","sizes":"(min-width: 502px) 502px, 100vw"},"sources":[{"srcSet":"/static/eb4749c9cfc9ecf498eb8a6b8daaf25f/0c07c/ovomind.webp 126w,\n/static/eb4749c9cfc9ecf498eb8a6b8daaf25f/92db7/ovomind.webp 251w,\n/static/eb4749c9cfc9ecf498eb8a6b8daaf25f/dd85a/ovomind.webp 502w","type":"image/webp","sizes":"(min-width: 502px) 502px, 100vw"}]},"width":502,"height":502}}},"title":"Emotion-driven audio-visual game design using AI","link":"https://www.aim.qmul.ac.uk/"},"id":"2a599d02-b171-52cb-9a02-3e3a68f8e877"},{"frontmatter":{"partner":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/e9ef6/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/03bfb/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6224a/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/41b67/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/5e2d0/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/36fd4/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"RUDIMENTS: Reflective Understanding of Digital Instruments as Musical Entanglements","link":"https://gtr.ukri.org/projects?ref=EP%2FX023478%2F1"},"id":"1ca5c79d-6979-5773-b66a-2baa00ee280e"},{"frontmatter":{"partner":"Spotify Ltd","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/d32b3bc89349e9cde8d09b1ed86ba3d8/ad86b/spotify.png","srcSet":"/static/d32b3bc89349e9cde8d09b1ed86ba3d8/cb344/spotify.png 480w,\n/static/d32b3bc89349e9cde8d09b1ed86ba3d8/6b240/spotify.png 960w,\n/static/d32b3bc89349e9cde8d09b1ed86ba3d8/ad86b/spotify.png 1920w","sizes":"(min-width: 1920px) 1920px, 100vw"},"sources":[{"srcSet":"/static/d32b3bc89349e9cde8d09b1ed86ba3d8/1cab1/spotify.webp 480w,\n/static/d32b3bc89349e9cde8d09b1ed86ba3d8/6886a/spotify.webp 960w,\n/static/d32b3bc89349e9cde8d09b1ed86ba3d8/79eca/spotify.webp 1920w","type":"image/webp","sizes":"(min-width: 1920px) 1920px, 100vw"}]},"width":1920,"height":1920}}},"title":"Industry-scale machine listening for music and audio data","link":"https://www.aim.qmul.ac.uk/"},"id":"bfb676c7-6999-5c79-9ec2-d275729deb5c"},{"frontmatter":{"partner":"Steinberg Media Technologies GmbH","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/7ee39456f0d4459d0fde983c8d26642a/bd51f/Steinberg-Logo.png","srcSet":"/static/7ee39456f0d4459d0fde983c8d26642a/ff8c7/Steinberg-Logo.png 750w,\n/static/7ee39456f0d4459d0fde983c8d26642a/1ca65/Steinberg-Logo.png 1500w,\n/static/7ee39456f0d4459d0fde983c8d26642a/bd51f/Steinberg-Logo.png 3000w","sizes":"(min-width: 3000px) 3000px, 100vw"},"sources":[{"srcSet":"/static/7ee39456f0d4459d0fde983c8d26642a/06b77/Steinberg-Logo.webp 750w,\n/static/7ee39456f0d4459d0fde983c8d26642a/b76c6/Steinberg-Logo.webp 1500w,\n/static/7ee39456f0d4459d0fde983c8d26642a/1e533/Steinberg-Logo.webp 3000w","type":"image/webp","sizes":"(min-width: 3000px) 3000px, 100vw"}]},"width":3000,"height":3000}}},"title":"Smart Channel Strip using Neural Audio Processing","link":"https://www.aim.qmul.ac.uk/"},"id":"fa01c1cf-86a7-58b6-a57b-a8579ae28bae"},{"frontmatter":{"partner":"Tape It GmbH","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/ee11d1f74157540a4add0e08794f858b/8de4e/tapeit.png","srcSet":"/static/ee11d1f74157540a4add0e08794f858b/a4976/tapeit.png 139w,\n/static/ee11d1f74157540a4add0e08794f858b/b71ea/tapeit.png 279w,\n/static/ee11d1f74157540a4add0e08794f858b/8de4e/tapeit.png 557w","sizes":"(min-width: 557px) 557px, 100vw"},"sources":[{"srcSet":"/static/ee11d1f74157540a4add0e08794f858b/ecfb2/tapeit.webp 139w,\n/static/ee11d1f74157540a4add0e08794f858b/d92b2/tapeit.webp 279w,\n/static/ee11d1f74157540a4add0e08794f858b/c13b9/tapeit.webp 557w","type":"image/webp","sizes":"(min-width: 557px) 557px, 100vw"}]},"width":557,"height":557}}},"title":"Deep learning for high-fidelity audio and music production","link":"https://www.aim.qmul.ac.uk/"},"id":"6091b7eb-fefc-597e-87ad-868ce8977148"},{"frontmatter":{"partner":"MUSIC Tribe Brands UK Limited","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/d1722eab64ccd54a66caf05e06a46447/8e0bd/music_tribe.jpg","srcSet":"/static/d1722eab64ccd54a66caf05e06a46447/ec0cc/music_tribe.jpg 313w,\n/static/d1722eab64ccd54a66caf05e06a46447/f3f35/music_tribe.jpg 626w,\n/static/d1722eab64ccd54a66caf05e06a46447/8e0bd/music_tribe.jpg 1251w","sizes":"(min-width: 1251px) 1251px, 100vw"},"sources":[{"srcSet":"/static/d1722eab64ccd54a66caf05e06a46447/c757a/music_tribe.webp 313w,\n/static/d1722eab64ccd54a66caf05e06a46447/4c5f3/music_tribe.webp 626w,\n/static/d1722eab64ccd54a66caf05e06a46447/01b4a/music_tribe.webp 1251w","type":"image/webp","sizes":"(min-width: 1251px) 1251px, 100vw"}]},"width":1251,"height":1251}}},"title":"Perceptual end to end learning for music understanding","link":"https://www.aim.qmul.ac.uk/"},"id":"47b58333-a892-50a7-a3b2-3d844f7d3fbf"},{"frontmatter":{"partner":"Steinberg Media Technologies GmbH","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/7ee39456f0d4459d0fde983c8d26642a/bd51f/Steinberg-Logo.png","srcSet":"/static/7ee39456f0d4459d0fde983c8d26642a/ff8c7/Steinberg-Logo.png 750w,\n/static/7ee39456f0d4459d0fde983c8d26642a/1ca65/Steinberg-Logo.png 1500w,\n/static/7ee39456f0d4459d0fde983c8d26642a/bd51f/Steinberg-Logo.png 3000w","sizes":"(min-width: 3000px) 3000px, 100vw"},"sources":[{"srcSet":"/static/7ee39456f0d4459d0fde983c8d26642a/06b77/Steinberg-Logo.webp 750w,\n/static/7ee39456f0d4459d0fde983c8d26642a/b76c6/Steinberg-Logo.webp 1500w,\n/static/7ee39456f0d4459d0fde983c8d26642a/1e533/Steinberg-Logo.webp 3000w","type":"image/webp","sizes":"(min-width: 3000px) 3000px, 100vw"}]},"width":3000,"height":3000}}},"title":"Optical music recognition using deep learning","link":"https://www.aim.qmul.ac.uk/"},"id":"208a808b-fc90-5d7d-aaeb-5a256b7daccb"},{"frontmatter":{"partner":"Universal Music Group","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/7c901bdb79dfa3227f67846e9be24dc0/d25c2/universal.jpg","srcSet":"/static/7c901bdb79dfa3227f67846e9be24dc0/c378e/universal.jpg 250w,\n/static/7c901bdb79dfa3227f67846e9be24dc0/f7896/universal.jpg 500w,\n/static/7c901bdb79dfa3227f67846e9be24dc0/d25c2/universal.jpg 1000w","sizes":"(min-width: 1000px) 1000px, 100vw"},"sources":[{"srcSet":"/static/7c901bdb79dfa3227f67846e9be24dc0/eac41/universal.webp 250w,\n/static/7c901bdb79dfa3227f67846e9be24dc0/78725/universal.webp 500w,\n/static/7c901bdb79dfa3227f67846e9be24dc0/5406a/universal.webp 1000w","type":"image/webp","sizes":"(min-width: 1000px) 1000px, 100vw"}]},"width":1000,"height":1000}}},"title":"Deep learning and multi-modal models for the music industry","link":"https://www.aim.qmul.ac.uk/"},"id":"e1ddccd6-0b37-5671-94f5-d376530be6ef"},{"frontmatter":{"partner":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#d81848","images":{"fallback":{"src":"/static/127047931552f881e2d4827dff27579b/fc66a/royal_society.jpg","srcSet":"/static/127047931552f881e2d4827dff27579b/ba76f/royal_society.jpg 354w,\n/static/127047931552f881e2d4827dff27579b/874ca/royal_society.jpg 709w,\n/static/127047931552f881e2d4827dff27579b/fc66a/royal_society.jpg 1417w","sizes":"(min-width: 1417px) 1417px, 100vw"},"sources":[{"srcSet":"/static/127047931552f881e2d4827dff27579b/8b24f/royal_society.webp 354w,\n/static/127047931552f881e2d4827dff27579b/c623d/royal_society.webp 709w,\n/static/127047931552f881e2d4827dff27579b/ba405/royal_society.webp 1417w","type":"image/webp","sizes":"(min-width: 1417px) 1417px, 100vw"}]},"width":1417,"height":1417}}},"title":"Unsupervised detection of sound events for complex audio","link":"https://royalsociety.org/grants-schemes-awards/grants/international-exchanges/"},"id":"4bc4a303-d494-50ab-8a24-903a404e1f01"}]}}}