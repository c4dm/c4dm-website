{"data":{"about":{"html":"<p>The <em><strong>Centre for Digital Music</strong></em> is a world-leading, multidisciplinary research group in the field of music &#x26; audio technology.</p>\n<!-- <p style=\"color: red\">**THIS SEEMS TO BE THE ONLY SUPPORTED WAY OF IMPORTING TWITTER TWEETS IN GATSBY 5 AT THE MOMENT, AFAIK IT MEANS THAT EACH \nTWEET HAS TO BE MANUALLY IMPORTED INTO AN MD FILE...**</p>\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">This is what we do: <a href=\"https://t.co/pkyS6IcIUy\">https://t.co/pkyS6IcIUy</a> - an excellent video intro to the wonderful researchers of <a href=\"https://twitter.com/c4dm?ref_src=twsrc%5Etfw\">@c4dm</a>. <a href=\"https://twitter.com/QMEECS?ref_src=twsrc%5Etfw\">@QMEECS</a> <a href=\"https://twitter.com/QMUL?ref_src=twsrc%5Etfw\">@QMUL</a> <a href=\"https://twitter.com/hashtag/research?src=hash&amp;ref_src=twsrc%5Etfw\">#research</a></p>&mdash; C4DM at QMUL (@c4dm) <a href=\"https://twitter.com/c4dm/status/857989625922695173?ref_src=twsrc%5Etfw\">April 28, 2017</a></blockquote> -->","frontmatter":{"title":"About the centre","video":"https://www.youtube.com/embed/YIFgS8she58","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/c138fbce66e709a3f503405435de2f2c/354fd/c4dm.png","srcSet":"/static/c138fbce66e709a3f503405435de2f2c/0fc07/c4dm.png 100w,\n/static/c138fbce66e709a3f503405435de2f2c/bc685/c4dm.png 200w,\n/static/c138fbce66e709a3f503405435de2f2c/354fd/c4dm.png 400w,\n/static/c138fbce66e709a3f503405435de2f2c/7ef25/c4dm.png 800w","sizes":"(min-width: 400px) 400px, 100vw"},"sources":[{"srcSet":"/static/c138fbce66e709a3f503405435de2f2c/29e9d/c4dm.webp 100w,\n/static/c138fbce66e709a3f503405435de2f2c/2f9ed/c4dm.webp 200w,\n/static/c138fbce66e709a3f503405435de2f2c/ece87/c4dm.webp 400w,\n/static/c138fbce66e709a3f503405435de2f2c/4bc26/c4dm.webp 800w","type":"image/webp","sizes":"(min-width: 400px) 400px, 100vw"}]},"width":400,"height":60}}}}},"projects":{"nodes":[{"fields":{"slug":"/projects/Benetos-L-Acoustics"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6c0ff/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/de3a1/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/30cdc/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6c0ff/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/c65bc/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/078c3/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/3b6e5/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"Online speech enhancement in scenarios with low direct-to-reverberant-ratio","author":"Dr Emmanouil Benetos (PI), Dr Aidan Hogg (CI)","date":null,"link":"https://www.l-acoustics.com/"},"html":"","id":"ce65fc6c-7228-5805-a9b2-6e14e5fd5086"},{"fields":{"slug":"/projects/Benetos-Algorivm"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png","srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/2fd20/IUK.png 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/de391/IUK.png 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png 500w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[{"srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/d66e1/IUK.webp 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/e7160/IUK.webp 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/5f169/IUK.webp 500w","type":"image/webp","sizes":"(min-width: 500px) 500px, 100vw"}]},"width":500,"height":500}}},"title":"Project Maestro - AI Musical Analysis Platform","author":"Dr Emmanouil Benetos (PI), Prof Simon Dixon (CI)","date":null,"link":"https://www.ukri.org/councils/innovate-uk/"},"html":"","id":"78c348d8-d78f-5acf-8441-382bc6c4d791"},{"fields":{"slug":"/projects/Benetos-Moises"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6c0ff/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/de3a1/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/30cdc/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6c0ff/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/c65bc/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/078c3/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/3b6e5/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"Enhancing lyrics transcription with open-source architectures and fine-tuning techniques","author":"Dr Emmanouil Benetos (PI)","date":null,"link":"https://moises.ai/"},"html":"","id":"d61977ff-9345-55a4-b85e-44caffa4a7f0"},{"fields":{"slug":"/projects/Dixon-assessment"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6c0ff/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/de3a1/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/30cdc/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6c0ff/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/c65bc/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/078c3/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/3b6e5/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"Music Performance Assessment and Feedback","author":"Prof Simon Dixon (PI), Dr Emmanouil Benetos (CI)","date":null,"link":null},"html":"","id":"68ee56ea-59b7-58de-a8c9-805c4aba4357"},{"fields":{"slug":"/projects/Dixon-guitar-transcription"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png","srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/2fd20/IUK.png 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/de391/IUK.png 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png 500w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[{"srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/d66e1/IUK.webp 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/e7160/IUK.webp 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/5f169/IUK.webp 500w","type":"image/webp","sizes":"(min-width: 500px) 500px, 100vw"}]},"width":500,"height":500}}},"title":"High Resolution Guitar Transcription","author":"Prof Simon Dixon (PI)","date":null,"link":null},"html":"","id":"4dee84b0-faa4-549a-a883-d4de0a21e205"},{"fields":{"slug":"/projects/Reiss-ProStyle"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png","srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/2fd20/IUK.png 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/de391/IUK.png 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png 500w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[{"srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/d66e1/IUK.webp 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/e7160/IUK.webp 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/5f169/IUK.webp 500w","type":"image/webp","sizes":"(min-width: 500px) 500px, 100vw"}]},"width":500,"height":500}}},"title":"Music Production Style Transfer (ProStyle)","author":"Prof Josh Reiss (PI)","date":null,"link":"https://www.musicweek.com/digital/read/audio-production-start-up-roex-awarded-250-000-grant-by-innovate-uk-s-ai-funding-competition/089706"},"html":"","id":"473b36de-2173-5bac-bfac-c8d0c8b27c41"}]},"news":{"nodes":[{"fields":{"slug":"/news/2024-07-30.C4DM-Seminar_Hyon_Kim"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6e45d55cd3da3f0a9c12568e44160cff/e8b76/placeholder.png","srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/30cdc/placeholder.png 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/c7240/placeholder.png 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/e8b76/placeholder.png 1200w","sizes":"(min-width: 1200px) 1200px, 100vw"},"sources":[{"srcSet":"/static/6e45d55cd3da3f0a9c12568e44160cff/078c3/placeholder.webp 300w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/6d09e/placeholder.webp 600w,\n/static/6e45d55cd3da3f0a9c12568e44160cff/83805/placeholder.webp 1200w","type":"image/webp","sizes":"(min-width: 1200px) 1200px, 100vw"}]},"width":1200,"height":1200}}},"title":"C4DM Seminar:  Hyon Kim","author":"Admin","date":"Tue 30 Jul 2024"},"html":"<h3>C4DM Seminar: Hyon Kim: Score Informed Note-level MIDI Velocity Estimation and Its Transcription into Symbolics</h3>\n<hr>\n<h4>QMUL, School of Electronic Engineering and Computer Science</h4>\n<h4>Centre for Digital Music Seminar Series</h4>\n<p><strong>Seminar by:</strong><br>\nHyon Kim</p>\n<p><strong>Date/time:  Tuesday, 30th July 2024, 3pm</strong></p>\n<p>**Location: G2, ENG, Mile End Campus, QMUL, E1 4NS **\nZoom: <a href=\"https://qmul-ac-uk.zoom.us/j/9798452959\">https://qmul-ac-uk.zoom.us/j/9798452959</a></p>\n<h2><b>Title</b>: Score Informed Note-level MIDI Velocity Estimation and Its Transcription into Symbolics</h2>\n<p><b>Abstract</b>: It is a well known fact that the dynamics in piano performance gives significant effect in expressiveness. Taking the polyphonic nature of the instrument into account, analysing information to form dynamics for each performed note has significant meaning to understand piano performance in a quantitative way. It is also a key element in an education context for piano learners.　\nIn this study, we developed a model for estimating MIDI velocity for each note, as one of indicators to represent loudness, with a condition of score by a Deep Neural Network (DNN) and Feature-wise Linear Modulation (FiLM) conditioning. Additionally, we have conducted research to map MIDI velocities to dynamics markings by combining performance MIDI roll and MusicXML information into one sequence.</p>\n<p><b>Bio</b>: Hyon Kim is a PhD student at Music Technology Group, Universitat Pompeu Fabra under the supervision of Prof. Xavier Serra. Currently, Hyon is a Visiting Researcher at C4DM, QMUL, working under the supervision of Dr. Emmanouil Benetos. His research interests include modeling the dynamic information of piano performance and transcribing it into MIDI roll and symbolic representations using various DNN methods in a multimodal fashion, incorporating both score and audio data.</p>","id":"de847f8c-3aaf-5694-a7da-262f0eef140d"},{"fields":{"slug":"/news/2024-07-25.C4DM-at_IJCAI_2024"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/b1555465f2a9005accfd26895310ca00/6fc22/IJCAI-2024.png","srcSet":"/static/b1555465f2a9005accfd26895310ca00/7d8ec/IJCAI-2024.png 105w,\n/static/b1555465f2a9005accfd26895310ca00/6f644/IJCAI-2024.png 211w,\n/static/b1555465f2a9005accfd26895310ca00/6fc22/IJCAI-2024.png 421w","sizes":"(min-width: 421px) 421px, 100vw"},"sources":[{"srcSet":"/static/b1555465f2a9005accfd26895310ca00/20fdf/IJCAI-2024.webp 105w,\n/static/b1555465f2a9005accfd26895310ca00/16179/IJCAI-2024.webp 211w,\n/static/b1555465f2a9005accfd26895310ca00/e0af3/IJCAI-2024.webp 421w","type":"image/webp","sizes":"(min-width: 421px) 421px, 100vw"}]},"width":421,"height":421}}},"title":"C4DM at IJCAI 2024","author":"Emmanouil Benetos","date":"Thu 25 Jul 2024"},"html":"<p>On 3-9 August, C4DM PhD student <a href=\"https://ldzhangyx.github.io/\">Yixiao Zhang</a> will participate in the <b><a href=\"https://ijcai24.org/\">33rd International Joint Conference on Artificial Intelligence (IJCAI 2024)</a></b> taking place in Jeju, South Korea. IJCAI has remained the premier conference bringing together the international AI community in communicating the advances and celebrating the achievements of artificial intelligence research and practice.</p>\n<p>At the conference, Yixiao will present the following paper as part of the <a href=\"https://ijcai24.org/ai-arts-creativity-special-track-accepted-papers/\">AI, Arts &#x26; Creativity Special Track</a>:</p>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2402.06178\">MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models</a>, by Yixiao Zhang, Yukara Ikemiya, Gus Xia, Naoki Murata, Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Yuki Mitsufuji, Simon Dixon</li>\n</ul>\n<p>See you in Jeju!</p>","id":"115c3260-ff2b-598c-8693-3bb28626870c"},{"fields":{"slug":"/news/2024-07-19.C4DM-at_DMLR_2024"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/fe10f44549fb5a9622279157ac1cd6b8/47930/DMLR.jpg","srcSet":"/static/fe10f44549fb5a9622279157ac1cd6b8/e07e1/DMLR.jpg 100w,\n/static/fe10f44549fb5a9622279157ac1cd6b8/dd515/DMLR.jpg 200w,\n/static/fe10f44549fb5a9622279157ac1cd6b8/47930/DMLR.jpg 400w","sizes":"(min-width: 400px) 400px, 100vw"},"sources":[{"srcSet":"/static/fe10f44549fb5a9622279157ac1cd6b8/d8057/DMLR.webp 100w,\n/static/fe10f44549fb5a9622279157ac1cd6b8/2e34e/DMLR.webp 200w,\n/static/fe10f44549fb5a9622279157ac1cd6b8/416c3/DMLR.webp 400w","type":"image/webp","sizes":"(min-width: 400px) 400px, 100vw"}]},"width":400,"height":400}}},"title":"C4DM at DMLR @ ICML 2024","author":"Emmanouil Benetos","date":"Fri 19 Jul 2024"},"html":"<p>On 21-27 July 2024, C4DM researchers will participate at the <b><a href=\"https://icml.cc/Conferences/2024\">Forty-first International Conference on Machine Learning (ICML 2024)</a></b>, taking place in Vienna, Austria. ICML is the leading international academic conference in machine learning, supported by the International Machine Learning Society (IMLS).</p>\n<p>There, C4DM PhD student Ilaria Manco will be presenting the following paper at the <a href=\"https://dmlr.ai/\">ICLR Data-centric Machine Learning Research workshop (DMLR)</a>:</p>\n<ul>\n<li>Evaluating music understanding in multimodal audio-language models, by Benno Weck, Ilaria Manco, Emmanouil Benetos, Elio Quinton, George Fazekas, Dmitry Bogdanov</li>\n</ul>\n<p>See you all at ICML!</p>","id":"41cc56d8-1726-5693-99b4-d8b405a73e38"},{"fields":{"slug":"/news/2024-07-15.New-PhD_Yamaha"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/040073a0863ddefed87d40085e8120d8/86b19/aim-small-logo.png","srcSet":"/static/040073a0863ddefed87d40085e8120d8/559e8/aim-small-logo.png 85w,\n/static/040073a0863ddefed87d40085e8120d8/19b99/aim-small-logo.png 170w,\n/static/040073a0863ddefed87d40085e8120d8/86b19/aim-small-logo.png 340w","sizes":"(min-width: 340px) 340px, 100vw"},"sources":[{"srcSet":"/static/040073a0863ddefed87d40085e8120d8/8f0cc/aim-small-logo.webp 85w,\n/static/040073a0863ddefed87d40085e8120d8/5376c/aim-small-logo.webp 170w,\n/static/040073a0863ddefed87d40085e8120d8/89ae4/aim-small-logo.webp 340w","type":"image/webp","sizes":"(min-width: 340px) 340px, 100vw"}]},"width":340,"height":340}}},"title":"New industry-funded PhD position","author":"Admin","date":"Mon 15 Jul 2024"},"html":"<p>We have one industry-funded PhD position to join <a href=\"https://www.c4dm.eecs.qmul.ac.uk/\">C4DM</a> and the <a href=\"https://www.aim.qmul.ac.uk/\">UKRI CDT in AI and Music</a> in September 2024, on the topic of <strong><a href=\"https://www.aim.qmul.ac.uk/wp-content/uploads/2024/07/Topic-Smart-EQ-description-Sept-24-2.pdf\">Smart EQ: Personalizing Audio with Context-aware AI using Listener Preferences and Psychological Factors</a></strong> supervised by <a href=\"https://comma.eecs.qmul.ac.uk/\">Dr Charalampos Saitis</a> and <a href=\"https://eecs.qmul.ac.uk/~gyorgyf/index.html\">Dr George Fazekas</a> in collaboration with Yamaha.</p>\n<p><a href=\"https://www.aim.qmul.ac.uk/apply/\">Apply here</a> before 26th August.</p>\n<p>Interested candidates should reach out to the supervisors by email: <a href=\"mailto:c.saitis@qmul.ac.uk\">c.saitis@qmul.ac.uk</a> and <a href=\"mailto:george.fazekas@qmul.ac.uk\">george.fazekas@qmul.ac.uk</a>.</p>","id":"e925c13b-0e20-5f93-874d-bedfd5a69a94"},{"fields":{"slug":"/news/2024-07-05.C4DM-study_pop_song_melodies"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#081818","images":{"fallback":{"src":"/static/6229b0afbe19c353213a241e7279156c/2497f/iStock-1913125761.jpg","srcSet":"/static/6229b0afbe19c353213a241e7279156c/248cc/iStock-1913125761.jpg 313w,\n/static/6229b0afbe19c353213a241e7279156c/8414e/iStock-1913125761.jpg 625w,\n/static/6229b0afbe19c353213a241e7279156c/2497f/iStock-1913125761.jpg 1250w","sizes":"(min-width: 1250px) 1250px, 100vw"},"sources":[{"srcSet":"/static/6229b0afbe19c353213a241e7279156c/f7ab9/iStock-1913125761.webp 313w,\n/static/6229b0afbe19c353213a241e7279156c/c3c5b/iStock-1913125761.webp 625w,\n/static/6229b0afbe19c353213a241e7279156c/03ce1/iStock-1913125761.webp 1250w","type":"image/webp","sizes":"(min-width: 1250px) 1250px, 100vw"}]},"width":1250,"height":1250}}},"title":"C4DM Study finds popular song melodies have become simpler over time","author":"Emmanouil Benetos","date":"Fri 05 Jul 2024"},"html":"<p>Melodies of popular songs have become simpler since the 1950s, according to a study carried out by C4DM PhD student <a href=\"https://www.qmul.ac.uk/eecs/people/profiles/hamiltonmadelineann.html\">Madeline Hamilton</a> and C4DM academic <a href=\"https://www.marcus-pearce.com/\">Dr Marcus Pearce</a>, published in the journal Scientific Reports. The full paper can be found at: : <a href=\"https://www.nature.com/articles/s41598-024-64571-x\">https://www.nature.com/articles/s41598-024-64571-x</a></p>\n<p>An analysis of hundreds of chart hits from the past 70 years has shown “a significant decline” in the complexity of rhythm and pitch in song melodies. They said the biggest transitions – or “bursts of change” – occurred in the years 1975 and 2000 – when music genres such as new wave, disco and stadium rock started gaining popularity in the mid-1970s, and hip-hop became more prominent in the early Noughties. The researchers said the findings suggest complexity and creative expression in popular music is shifting away from melody and towards other elements such as quality of the sound.</p>\n<p>See the full newsitem published in the Independent: <a href=\"https://www.independent.co.uk/arts-entertainment/music/news/top-song-melodies-simpler-study-b2574633.html\">https://www.independent.co.uk/arts-entertainment/music/news/top-song-melodies-simpler-study-b2574633.html</a></p>","id":"c404174d-8683-5050-841a-b426037fcc54"},{"fields":{"slug":"/news/2024-06-24.C4DM-academic_at_AI_chamber_music_symposium"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/0f7df906e23f5363c766cfa5e0df523a/f4df4/ccdd-event-poster.png","srcSet":"/static/0f7df906e23f5363c766cfa5e0df523a/b4532/ccdd-event-poster.png 281w,\n/static/0f7df906e23f5363c766cfa5e0df523a/31998/ccdd-event-poster.png 563w,\n/static/0f7df906e23f5363c766cfa5e0df523a/f4df4/ccdd-event-poster.png 1125w","sizes":"(min-width: 1125px) 1125px, 100vw"},"sources":[{"srcSet":"/static/0f7df906e23f5363c766cfa5e0df523a/a37a7/ccdd-event-poster.webp 281w,\n/static/0f7df906e23f5363c766cfa5e0df523a/0fbb3/ccdd-event-poster.webp 563w,\n/static/0f7df906e23f5363c766cfa5e0df523a/94e11/ccdd-event-poster.webp 1125w","type":"image/webp","sizes":"(min-width: 1125px) 1125px, 100vw"}]},"width":1125,"height":1125}}},"title":"C4DM academic at AI & Chamber Music Symposium","author":"Admin","date":"Mon 24 Jun 2024"},"html":"<p>On 24 June, C4DM academic Johan Pauwels will give a talk on \"Opportunities Unleashed by AI for Music\" at <a href=\"https://ilcs.sas.ac.uk/events/critical-creative-digital-dynamics-a-symposium-ai-digital-innovations-inter-art-chamber-0\">Critical &#x26; Creative Digital Dynamics: A Symposium on AI &#x26; Digital Innovations for Inter-art Chamber Music\nPractices</a>. The\nevent is hosted by the <a href=\"https://ilcs.sas.ac.uk/\">Institute of Languages, Cultures and Societies</a> at the <a href=\"https://ilcs.sas.ac.uk/\">School of Advanced Study, University of London</a>. It will take place between 10am and 7pm at <a href=\"https://www.openstreetmap.org/#map=16/51.5210/-0.1314\">Senate\nHouse Library, Malet Street, WC1E 7HU London</a>.</p>","id":"8c16cf0d-e7fa-5607-99b6-c04571ecbefb"}]}}}