{"data":{"projects":{"nodes":[{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["Industry funding"],"title":"Music Performance Assessment and Feedback","author":"Prof Simon Dixon (PI), Dr Emmanouil Benetos (CI)","begin":"2024","end":"2025","grant":"Industry/contract research","amount":"£250,000","link":"https://www.c4dm.eecs.qmul.ac.uk/"},"id":"68ee56ea-59b7-58de-a8c9-805c4aba4357"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png","srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/2fd20/IUK.png 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/de391/IUK.png 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png 500w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[{"srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/d66e1/IUK.webp 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/e7160/IUK.webp 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/5f169/IUK.webp 500w","type":"image/webp","sizes":"(min-width: 500px) 500px, 100vw"}]},"width":500,"height":500}}},"status":"active","tags":["UKRI funding"],"title":"High Resolution Guitar Transcription","author":"Prof Simon Dixon (PI)","begin":"2024","end":"2024","grant":"Innovate UK ICURe Programme DSMAR24-06 / 521975189","amount":"£2,500","link":"https://www.c4dm.eecs.qmul.ac.uk/"},"id":"4dee84b0-faa4-549a-a883-d4de0a21e205"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png","srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/2fd20/IUK.png 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/de391/IUK.png 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png 500w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[{"srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/d66e1/IUK.webp 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/e7160/IUK.webp 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/5f169/IUK.webp 500w","type":"image/webp","sizes":"(min-width: 500px) 500px, 100vw"}]},"width":500,"height":500}}},"status":"active","tags":["UKRI funding"],"title":"Music Production Style Transfer (ProStyle)","author":"Prof Josh Reiss (PI)","begin":"2024","end":"2025","grant":"Innovate UK Creative Catalyst: AI in the Music Industry","amount":"£74,786","link":"https://www.musicweek.com/digital/read/audio-production-start-up-roex-awarded-250-000-grant-by-innovate-uk-s-ai-funding-competition/089706"},"id":"473b36de-2173-5bac-bfac-c8d0c8b27c41"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png","srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/2fd20/IUK.png 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/de391/IUK.png 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png 500w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[{"srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/d66e1/IUK.webp 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/e7160/IUK.webp 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/5f169/IUK.webp 500w","type":"image/webp","sizes":"(min-width: 500px) 500px, 100vw"}]},"width":500,"height":500}}},"status":"active","tags":["UKRI funding"],"title":"StudioSync: AI productivity tools for record labels in the management of musical recordings and creator metadata","author":"Prof Mark Sandler (PI), Dr Mathieu Barthet (CI)","begin":"2024","end":"2025","grant":"Innovate UK Collaborative AI Solutions","amount":"£304,918","link":"https://www.qmul.ac.uk/media/news/2024/se/ai-in-music-queen-mary-begins-new-research-partnerships-.html"},"id":"78ac4947-ec1c-5c8d-a90a-f26dadceec5b"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png","srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/2fd20/IUK.png 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/de391/IUK.png 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png 500w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[{"srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/d66e1/IUK.webp 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/e7160/IUK.webp 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/5f169/IUK.webp 500w","type":"image/webp","sizes":"(min-width: 500px) 500px, 100vw"}]},"width":500,"height":500}}},"status":"active","tags":["UKRI funding"],"title":"Co-creator for songwriters & producers: generative AI Creator tools to boost efficiency of the creative process","author":"Prof Mark Sandler (PI), Dr Mathieu Barthet (CI), Dr Haim Dubossarsky (CI)","begin":"2024","end":"2025","grant":"Innovate UK Collaborative AI Solutions","amount":"£320,887","link":"https://www.qmul.ac.uk/media/news/2024/se/ai-in-music-queen-mary-begins-new-research-partnerships-.html"},"id":"b8b99902-0a45-5ad4-8dcd-c587e8c3dcc8"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png","srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/2fd20/IUK.png 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/de391/IUK.png 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/82c11/IUK.png 500w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[{"srcSet":"/static/4a9a1456d73a0d828225e48944ebd69a/d66e1/IUK.webp 125w,\n/static/4a9a1456d73a0d828225e48944ebd69a/e7160/IUK.webp 250w,\n/static/4a9a1456d73a0d828225e48944ebd69a/5f169/IUK.webp 500w","type":"image/webp","sizes":"(min-width: 500px) 500px, 100vw"}]},"width":500,"height":500}}},"status":"active","tags":["UKRI funding"],"title":"Fine-grained music source separation with deep learning models","author":"Dr Lin Wang (PI), Prof Mark Sandler (CI)","begin":"2024","end":"2025","grant":"Innovate UK Creative Catalyst: AI in the Music Industry","amount":"£48,144","link":"https://www.qmul.ac.uk/media/news/2024/se/ai-in-music-queen-mary-begins-new-research-partnerships-.html"},"id":"b36c6cb1-962d-5579-80ee-0dad4a16d698"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["Industry funding"],"title":"Style classification of podcasts using audio","author":"Dr Emmanouil Benetos (PI)","begin":"2024","end":"2026","grant":"Spotify Ltd, PhD studentship","amount":"£33,000","link":"https://research.atspotify.com/"},"id":"19d1254c-f423-52ab-ae78-51e201f32ab6"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/14ae7694223d03edb7966d74ea33ce18/82c11/RAEng.png","srcSet":"/static/14ae7694223d03edb7966d74ea33ce18/2fd20/RAEng.png 125w,\n/static/14ae7694223d03edb7966d74ea33ce18/de391/RAEng.png 250w,\n/static/14ae7694223d03edb7966d74ea33ce18/82c11/RAEng.png 500w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[{"srcSet":"/static/14ae7694223d03edb7966d74ea33ce18/d66e1/RAEng.webp 125w,\n/static/14ae7694223d03edb7966d74ea33ce18/e7160/RAEng.webp 250w,\n/static/14ae7694223d03edb7966d74ea33ce18/5f169/RAEng.webp 500w","type":"image/webp","sizes":"(min-width: 500px) 500px, 100vw"}]},"width":500,"height":500}}},"status":"active","tags":["UK national academy funding"],"title":"Resource-efficient Machine Listening","author":"Dr Emmanouil Benetos (PI)","begin":"2023","end":"2024","grant":"RAEng/Leverhulme Trust Research Fellowship LTRF2223-19-106","amount":"£52,455","link":"https://raeng.org.uk/programmes-and-prizes/programmes/uk-grants-and-prizes/support-for-research/research-awardees/leverhulme-awardees/leverhulme-trust-research-fellows-2023-2024/dr-emmanouil-benetos"},"id":"38a18c8b-2a57-5eb4-aacc-e53110561f62"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["Industry funding"],"title":"Modelling Jazz Piano: Symbolic Music Generation via Large-scale Automatic Transcription","author":"Prof Simon Dixon (PI)","begin":"2023","end":"2025","grant":"Yamaha Corporation, PhD studentship","amount":"£60,000","link":"https://www.yamaha.com/en/"},"id":"f1c3ee79-c274-565e-9dee-d93f648409a0"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["Industry funding"],"title":"New Methodologies for Efficient and Controllable Music Generation","author":"Dr George Fazekas (PI)","begin":"2023","end":"2027","grant":"Sony Europe B.V., PhD studentship","amount":"£150,000","link":"https://www.sony.co.uk/"},"id":"a3e9f3a1-9edd-50fe-b941-283fe6f7de85"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["Industry funding"],"title":"Beyond Supervised Learning for Musical Audio","author":"Dr George Fazekas (PI)","begin":"2023","end":"2027","grant":"Universal Music Group International Limited, PhD studentship","amount":"£61,268","link":"https://www.universalmusic.com/"},"id":"433744e4-ecdf-538d-903d-85748cab2ea6"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"complete","tags":["Industry funding"],"title":"Analysing User Activity for Improving Recommendations in Streaming Platforms","author":"Dr Charalampos Saitis (PI)","begin":"2023","end":"2023","grant":"BBC R&D, PhD internship","amount":"£9,834","link":"https://www.bbc.co.uk/rd"},"id":"9c81d979-b8f1-5368-b437-81d5da8b991d"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/1c64ecce121aafcd3ee5bb2486cc874c/5aead/sensingtheforest.png","srcSet":"/static/1c64ecce121aafcd3ee5bb2486cc874c/e9fba/sensingtheforest.png 50w,\n/static/1c64ecce121aafcd3ee5bb2486cc874c/15e42/sensingtheforest.png 100w,\n/static/1c64ecce121aafcd3ee5bb2486cc874c/5aead/sensingtheforest.png 200w","sizes":"(min-width: 200px) 200px, 100vw"},"sources":[{"srcSet":"/static/1c64ecce121aafcd3ee5bb2486cc874c/dbc4a/sensingtheforest.webp 50w,\n/static/1c64ecce121aafcd3ee5bb2486cc874c/d8057/sensingtheforest.webp 100w,\n/static/1c64ecce121aafcd3ee5bb2486cc874c/2e34e/sensingtheforest.webp 200w","type":"image/webp","sizes":"(min-width: 200px) 200px, 100vw"}]},"width":200,"height":200}}},"status":"active","tags":["UKRI funding"],"title":"Sensing the Forest: Let the Forest Speak using the Internet of Things, Acoustic Ecology and Creative AI","author":"Dr Anna Xambó (PI), Dr Peter Batchelor (CI, De Montfort University), Dr Krishna Nama Manjunatha (CI, De Montfort University), Dr Michael Bell (CI, Forest Research), Dr Georgios Xenakis (CI, Forest Research)","begin":"2023","end":"2025","grant":"AHRC Grant AH/X011585/1","amount":"£207,479","link":"https://sensingtheforest.github.io/"},"id":"0f2ce565-3933-5cf2-a679-8303dd57f81f"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["Industry funding"],"title":"Performance Rendering for Music Generation Systems","author":"Prof Simon Dixon (PI)","begin":"2022","end":"2026","grant":"DAACI Ltd, PhD studentship","amount":"£140,000","link":"https://daaci.com/"},"id":"780d9bfc-fda8-5320-aa0c-0a93788ae549"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"complete","tags":["Industry funding"],"title":"Investigating mental models of DAW software use by visually-impaired musicians","author":"Prof Andrew McPherson (PI)","begin":"2022","end":"2023","grant":"Ableton AG, Contract research","amount":"£97,000","link":"https://www.ableton.com/en/"},"id":"bb3749c9-6ae3-5fe7-aa69-410ef525d860"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"complete","tags":["Industry funding"],"title":"Deep learning technologies for multi-instrument automatic music transcription","author":"Dr Emmanouil Benetos (PI), Prof Simon Dixon (CI)","begin":"2022","end":"2023","grant":"Huawei Technologies Düsseldorf, Contract research","amount":"£252,000","link":"https://huawei.eu/"},"id":"e3b9fcbc-6097-521f-8d9c-94d239cca557"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/96e93ddaa92c9375174d9c309c3bed43/a764f/digitaljazz.jpg","srcSet":"/static/96e93ddaa92c9375174d9c309c3bed43/fb67e/digitaljazz.jpg 480w,\n/static/96e93ddaa92c9375174d9c309c3bed43/3059d/digitaljazz.jpg 960w,\n/static/96e93ddaa92c9375174d9c309c3bed43/a764f/digitaljazz.jpg 1920w","sizes":"(min-width: 1920px) 1920px, 100vw"},"sources":[{"srcSet":"/static/96e93ddaa92c9375174d9c309c3bed43/3a3a2/digitaljazz.webp 480w,\n/static/96e93ddaa92c9375174d9c309c3bed43/bde8a/digitaljazz.webp 960w,\n/static/96e93ddaa92c9375174d9c309c3bed43/c512e/digitaljazz.webp 1920w","type":"image/webp","sizes":"(min-width: 1920px) 1920px, 100vw"}]},"width":1920,"height":1080}}},"status":"complete","tags":["UKRI funding"],"title":"New Directions in Digital Jazz Studies: Music Information Retrieval and AI Support for Jazz Scholarship in Digital Archives","author":"Dr Tillman Weyde (City, PI), Prof Simon Dixon (CI), plus two others","begin":"2021","end":"2024","grant":"AHRC grant AH/V009699/1","amount":"£50,845 (QMUL), £202,566 (total)","link":"https://gtr.ukri.org/projects?ref=AH%2FV009699%2F1"},"id":"b182ef18-382f-5f58-a1b0-2fe3b5667bd1"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/ab849585d66cbe4457ad55b0fdc5e451/0a45a/bela.jpg","srcSet":"/static/ab849585d66cbe4457ad55b0fdc5e451/1a361/bela.jpg 225w,\n/static/ab849585d66cbe4457ad55b0fdc5e451/cd18a/bela.jpg 450w,\n/static/ab849585d66cbe4457ad55b0fdc5e451/0a45a/bela.jpg 900w","sizes":"(min-width: 900px) 900px, 100vw"},"sources":[{"srcSet":"/static/ab849585d66cbe4457ad55b0fdc5e451/252a0/bela.webp 225w,\n/static/ab849585d66cbe4457ad55b0fdc5e451/2890f/bela.webp 450w,\n/static/ab849585d66cbe4457ad55b0fdc5e451/3987a/bela.webp 900w","type":"image/webp","sizes":"(min-width: 900px) 900px, 100vw"}]},"width":900,"height":900}}},"status":"active","tags":["UK national academy funding"],"title":"Bela / Royal Academy of Engineering Senior Research Fellow in Embedded Music Computing","author":"Prof Andrew McPherson (PI)","begin":"2021","end":"2026","grant":"RAEng Senior Research Fellowship","amount":"£208,776","link":"https://www.raeng.org.uk/grants-prizes/grants/support-for-research/research-chairs/current-and-recent-awards"},"id":"b49fde0c-1a42-5815-8c73-117d498a7400"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/c993712101c8512ecb7672308c273663/b8d58/bridgingthegap.png","srcSet":"/static/c993712101c8512ecb7672308c273663/3c983/bridgingthegap.png 384w,\n/static/c993712101c8512ecb7672308c273663/ad503/bridgingthegap.png 768w,\n/static/c993712101c8512ecb7672308c273663/b8d58/bridgingthegap.png 1536w","sizes":"(min-width: 1536px) 1536px, 100vw"},"sources":[{"srcSet":"/static/c993712101c8512ecb7672308c273663/c0efa/bridgingthegap.webp 384w,\n/static/c993712101c8512ecb7672308c273663/a9cbf/bridgingthegap.webp 768w,\n/static/c993712101c8512ecb7672308c273663/0300a/bridgingthegap.webp 1536w","type":"image/webp","sizes":"(min-width: 1536px) 1536px, 100vw"}]},"width":1536,"height":1079}}},"status":"active","tags":["UKRI funding"],"title":"Bridging the Gap - visually impaired and sighted music producers working side by side","author":"Prof Franziska Schroeder (PI, QUB), Prof Andrew McPherson (CI, QMUL)","begin":"2021","end":"2024","grant":"AHRC Grant AH/V011340/1","amount":"£576,879 (total), £174,448 (QMUL)","link":"https://gtr.ukri.org/projects?ref=AH%2FV011340%2F1"},"id":"df4c77a3-f868-5e3c-aefb-6767162fc318"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f87838","images":{"fallback":{"src":"/static/d6b5df0c36ed85881d1237b2030f4625/c868e/dame.png","srcSet":"/static/d6b5df0c36ed85881d1237b2030f4625/c9352/dame.png 98w,\n/static/d6b5df0c36ed85881d1237b2030f4625/546fa/dame.png 196w,\n/static/d6b5df0c36ed85881d1237b2030f4625/c868e/dame.png 392w","sizes":"(min-width: 392px) 392px, 100vw"},"sources":[{"srcSet":"/static/d6b5df0c36ed85881d1237b2030f4625/f1ce5/dame.webp 98w,\n/static/d6b5df0c36ed85881d1237b2030f4625/cace6/dame.webp 196w,\n/static/d6b5df0c36ed85881d1237b2030f4625/7bd5a/dame.webp 392w","type":"image/webp","sizes":"(min-width: 392px) 392px, 100vw"}]},"width":392,"height":392}}},"status":"active","tags":["Industry funding"],"title":"Centre for Doctoral Training in Data-informed Audience-centric Media Engineering (DAME)","author":"Prof Mark Sandler (PI), Prof Andrea Cavallaro (CI), Prof Pat Healey (CI), Dr Gareth Tyson (CI), and Dr Charalampos Saitis (CI)","begin":"2021","end":"2024","grant":null,"amount":"£177,000 (standard stipend) + £27,000 (contribution from BBC)","link":"https://dame.qmul.ac.uk/"},"id":"e4433bb8-943f-519a-bc83-e592c3199df5"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6798bd0a21b481f294603af17e6e5c13/ebb6b/elderwellbeing.png","srcSet":"/static/6798bd0a21b481f294603af17e6e5c13/5293c/elderwellbeing.png 102w,\n/static/6798bd0a21b481f294603af17e6e5c13/12126/elderwellbeing.png 205w,\n/static/6798bd0a21b481f294603af17e6e5c13/ebb6b/elderwellbeing.png 409w","sizes":"(min-width: 409px) 409px, 100vw"},"sources":[{"srcSet":"/static/6798bd0a21b481f294603af17e6e5c13/cc485/elderwellbeing.webp 102w,\n/static/6798bd0a21b481f294603af17e6e5c13/be984/elderwellbeing.webp 205w,\n/static/6798bd0a21b481f294603af17e6e5c13/03dd7/elderwellbeing.webp 409w","type":"image/webp","sizes":"(min-width: 409px) 409px, 100vw"}]},"width":409,"height":406}}},"status":"active","tags":["UKRI funding"],"title":"Designing new musical technologies for older adults' wellbeing","author":"Dr Jennifer MacRitchie (PI, Sheffield), Prof Andrew McPherson (CI), and 2 others","begin":"2021","end":"2025","grant":"UKRI Future Leaders Fellowship","amount":"£946,672 (total), £24,879 (QMUL)","link":"https://gtr.ukri.org/projects?ref=MR%2FT040580%2F1"},"id":"c701f3d3-aeb3-55ff-8b41-f0e044fa5c2d"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6711458031491075c5c84e437de90c34/2fc4b/graphnex.png","srcSet":"/static/6711458031491075c5c84e437de90c34/cb66a/graphnex.png 95w,\n/static/6711458031491075c5c84e437de90c34/930a2/graphnex.png 190w,\n/static/6711458031491075c5c84e437de90c34/2fc4b/graphnex.png 380w","sizes":"(min-width: 380px) 380px, 100vw"},"sources":[{"srcSet":"/static/6711458031491075c5c84e437de90c34/fded6/graphnex.webp 95w,\n/static/6711458031491075c5c84e437de90c34/b5e25/graphnex.webp 190w,\n/static/6711458031491075c5c84e437de90c34/b8a7e/graphnex.webp 380w","type":"image/webp","sizes":"(min-width: 380px) 380px, 100vw"}]},"width":380,"height":217}}},"status":"active","tags":["UKRI funding"],"title":"GraphNEx: Graph Neural Networks for Explainable Artificial Intelligence","author":"Prof Andrea Cavallaro (QMUL PI), Dr Emmanouil Benetos (CI)","begin":"2021","end":"2024","grant":"CHIST-ERA / EPSRC grant EP/V062107/1","amount":"£293,434","link":"https://gtr.ukri.org/projects?ref=EP%2FV062107%2F1"},"id":"de18f20d-6c10-52d0-a7b0-4a8c9c7f8699"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"complete","tags":["Internal funding"],"title":"Seeing Music: An interactive digital exhibit on sensory variation and the cross-sensory experience of music","author":"Dr Charalampos Saitis (PI), Dr Christine Cuskley (Newcastle, CI)","begin":"2021","end":"2022","grant":"QMUL Centre for Public Engagement Large Grant","amount":"£9,783","link":"https://www.seeingmusic.app/"},"id":"ce64ac76-ecbc-5a07-a3e4-5713e2a6f9c1"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["Industry funding"],"title":"Smart Channel Strip using Neural Audio Processing","author":"Dr George Fazekas (PI)","begin":"2021","end":"2025","grant":"Steinberg Media Technologies GmbH, AIM CDT PhD studentship","amount":"£109,649","link":"https://www.aim.qmul.ac.uk/"},"id":"7c543bb2-3b4e-5d04-9f40-ff872301abb2"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#d81848","images":{"fallback":{"src":"/static/1e187cc77c6fcb842a39c90f6c47cbdb/5bec7/RS.png","srcSet":"/static/1e187cc77c6fcb842a39c90f6c47cbdb/b0e74/RS.png 72w,\n/static/1e187cc77c6fcb842a39c90f6c47cbdb/2c84b/RS.png 144w,\n/static/1e187cc77c6fcb842a39c90f6c47cbdb/5bec7/RS.png 288w","sizes":"(min-width: 288px) 288px, 100vw"},"sources":[{"srcSet":"/static/1e187cc77c6fcb842a39c90f6c47cbdb/de323/RS.webp 72w,\n/static/1e187cc77c6fcb842a39c90f6c47cbdb/1b3aa/RS.webp 144w,\n/static/1e187cc77c6fcb842a39c90f6c47cbdb/9fc01/RS.webp 288w","type":"image/webp","sizes":"(min-width: 288px) 288px, 100vw"}]},"width":288,"height":288}}},"status":"complete","tags":["UK national academy funding"],"title":"Unsupervised detection of sound events for complex audio","author":"Dr Emmanouil Benetos (PI), Dr Yanxiong Li (SCUT, CI)","begin":"2021","end":"2023","grant":"Royal Society International Exchanges grant IEC/NSFC/201382","amount":"£3,800","link":"https://royalsociety.org/grants-schemes-awards/grants/international-exchanges/"},"id":"d277b9ec-f5cb-534b-89d8-1d1dadab207f"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["Industry funding"],"title":"Emotion-driven audio-visual game design using AI","author":"Dr Mathieu Barthet (PI)","begin":"2020","end":"2025","grant":"OVOMIND SA, PhD studentship","amount":"£33,500","link":"https://www.ovomind.com/"},"id":"64742a28-2467-5100-9a45-5d37c884b80a"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080838","images":{"fallback":{"src":"/static/bd2eecf83bf5392a4ac7061919a52914/cd63e/cdtdata.png","srcSet":"/static/bd2eecf83bf5392a4ac7061919a52914/08744/cdtdata.png 145w,\n/static/bd2eecf83bf5392a4ac7061919a52914/3c29b/cdtdata.png 290w,\n/static/bd2eecf83bf5392a4ac7061919a52914/cd63e/cdtdata.png 579w","sizes":"(min-width: 579px) 579px, 100vw"},"sources":[{"srcSet":"/static/bd2eecf83bf5392a4ac7061919a52914/72079/cdtdata.webp 145w,\n/static/bd2eecf83bf5392a4ac7061919a52914/a7f7a/cdtdata.webp 290w,\n/static/bd2eecf83bf5392a4ac7061919a52914/ba6fb/cdtdata.webp 579w","type":"image/webp","sizes":"(min-width: 579px) 579px, 100vw"}]},"width":579,"height":579}}},"status":"active","tags":["UKRI funding"],"title":"Centre for Doctoral Training (CDT) in Data Centric Engineering","author":"Prof Eram Rizvi (PI), Prof Mark Sandler (CI), Prof Nick Bryan-Kinns (CI)","begin":"2020","end":"2028","grant":"EPSRC Training Grant EP/V519935/1","amount":"£1,629,373","link":"https://gtr.ukri.org/projects?ref=EP%2FV519935%2F1"},"id":"e68ade9f-702f-5695-9a7d-e2ab94af8c72"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/4d5f308fe2613c55bb6b0e19394b9fa9/4a49b/jade.jpg","srcSet":"/static/4d5f308fe2613c55bb6b0e19394b9fa9/b4dad/jade.jpg 320w,\n/static/4d5f308fe2613c55bb6b0e19394b9fa9/3440d/jade.jpg 640w,\n/static/4d5f308fe2613c55bb6b0e19394b9fa9/4a49b/jade.jpg 1280w","sizes":"(min-width: 1280px) 1280px, 100vw"},"sources":[{"srcSet":"/static/4d5f308fe2613c55bb6b0e19394b9fa9/c0bcc/jade.webp 320w,\n/static/4d5f308fe2613c55bb6b0e19394b9fa9/17574/jade.webp 640w,\n/static/4d5f308fe2613c55bb6b0e19394b9fa9/71d4d/jade.webp 1280w","type":"image/webp","sizes":"(min-width: 1280px) 1280px, 100vw"}]},"width":1280,"height":720}}},"status":"complete","tags":["UKRI funding"],"title":"JADE: Joint Academic Data science Endeavour","author":"Wesley Gavin Armour (PI, Oxford), Prof Mark Sandler (CI, QMUL), plus 24 others","begin":"2020","end":"2023","grant":"EPSRC Grant EP/T022205/1","amount":"£5,539,933","link":"https://gtr.ukri.org/projects?ref=EP%2FT022205%2F1"},"id":"d5e21c61-0716-5927-a348-94bb02b33cf6"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/b8946f2bde6c94fa8eeec891e90b1e6b/96aa8/metaphors.png","srcSet":"/static/b8946f2bde6c94fa8eeec891e90b1e6b/4015f/metaphors.png 93w,\n/static/b8946f2bde6c94fa8eeec891e90b1e6b/abab1/metaphors.png 185w,\n/static/b8946f2bde6c94fa8eeec891e90b1e6b/96aa8/metaphors.png 370w","sizes":"(min-width: 370px) 370px, 100vw"},"sources":[{"srcSet":"/static/b8946f2bde6c94fa8eeec891e90b1e6b/78b69/metaphors.webp 93w,\n/static/b8946f2bde6c94fa8eeec891e90b1e6b/c5b6a/metaphors.webp 185w,\n/static/b8946f2bde6c94fa8eeec891e90b1e6b/7fd3d/metaphors.webp 370w","type":"image/webp","sizes":"(min-width: 370px) 370px, 100vw"}]},"width":370,"height":370}}},"status":"complete","tags":["UK national academy funding"],"title":"Metaphors we listen with: the neural correlates of timbral brightness investigated by pitch-timbre interference and fMRI","author":"Dr Charalampos Saitis (PI), Dr Zachary Wallmark (CI, University of Oregon, US)","begin":"2020","end":"2022","grant":"British Academy, BA/Leverhulme Small Research Grants scheme, SRG1920/101673","amount":"£10,000","link":"http://eecs.qmul.ac.uk/profiles/saitischaralampos.html"},"id":"96ca2677-8048-5074-b2f5-385587b611f8"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["Industry funding"],"title":"Industry-scale machine listening for music and audio data","author":"Prof Simon Dixon (PI)","begin":"2020","end":"2024","grant":"Spotify Ltd, AIM CDT PhD studentship","amount":"£108,000","link":"https://www.aim.qmul.ac.uk/"},"id":"09dfe751-bb66-555e-8350-48997620240b"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/98704461ac8eeac7d8b8a64dc1520bf4/7a590/aimcdt.png","srcSet":"/static/98704461ac8eeac7d8b8a64dc1520bf4/4b686/aimcdt.png 154w,\n/static/98704461ac8eeac7d8b8a64dc1520bf4/d2213/aimcdt.png 308w,\n/static/98704461ac8eeac7d8b8a64dc1520bf4/7a590/aimcdt.png 615w","sizes":"(min-width: 615px) 615px, 100vw"},"sources":[{"srcSet":"/static/98704461ac8eeac7d8b8a64dc1520bf4/b2942/aimcdt.webp 154w,\n/static/98704461ac8eeac7d8b8a64dc1520bf4/46581/aimcdt.webp 308w,\n/static/98704461ac8eeac7d8b8a64dc1520bf4/fa942/aimcdt.webp 615w","type":"image/webp","sizes":"(min-width: 615px) 615px, 100vw"}]},"width":615,"height":615}}},"status":"active","tags":["UKRI funding"],"title":"UKRI Centre for Doctoral Training in Artificial Intelligence and Music (AIM)","author":"Prof Simon Dixon (PI), Dr Mathieu Barthet (CI), Dr Nick Bryan-Kinns (CI), Dr Gyorgy Fazekas (CI), Prof Mark Sandler (CI), Dr Andrew McPherson (CI), Dr Emmanouil Benetos (CI)","begin":"2019","end":"2027","grant":"EPSRC Grant EP/S022694/1","amount":"£6,240,207","link":"https://www.aim.qmul.ac.uk/"},"id":"237af1c8-14dc-5167-a5e1-fa55e6860dea"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"complete","tags":["Industry funding"],"title":"Perceptual Aspects of Broadcast Audio Mixing for the Hearing Impaired","author":"Prof Josh Reiss (PI)","begin":"2019","end":"2022","grant":"ICASE PhD studentship 2161145","amount":"£83,300 (standard stipend) + £27,600 (contribution from BBC)","link":"https://gtr.ukri.org/projects?ref=studentship-2161145"},"id":"b0e56d5e-60ea-538c-a7dc-40ed3b0dc194"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["Industry funding"],"title":"Optical music recognition using deep learning","author":"Dr George Fazekas (PI)","begin":"2019","end":"2024","grant":"Steinberg Media Technologies GmbH, AIM CDT PhD studentship","amount":"£109,649","link":"https://www.aim.qmul.ac.uk/"},"id":"c49d4daa-387f-5374-8b7b-f258d1a4d7a6"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"complete","tags":["Industry funding"],"title":"Perceptual end to end learning for music understanding","author":"Dr George Fazekas (PI)","begin":"2019","end":"2023","grant":"MUSIC Tribe Brands UK Limited, AIM CDT PhD studentship","amount":"£27,000 ","link":"https://www.aim.qmul.ac.uk/"},"id":"4544efbd-9cf2-5b05-bfa7-dfee028de7ee"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6cf2e7126aeb16a6a13f73a77f91491c/a89ca/universalaim.jpg","srcSet":"/static/6cf2e7126aeb16a6a13f73a77f91491c/96deb/universalaim.jpg 150w,\n/static/6cf2e7126aeb16a6a13f73a77f91491c/0fdf4/universalaim.jpg 300w,\n/static/6cf2e7126aeb16a6a13f73a77f91491c/a89ca/universalaim.jpg 600w","sizes":"(min-width: 600px) 600px, 100vw"},"sources":[{"srcSet":"/static/6cf2e7126aeb16a6a13f73a77f91491c/c65bc/universalaim.webp 150w,\n/static/6cf2e7126aeb16a6a13f73a77f91491c/078c3/universalaim.webp 300w,\n/static/6cf2e7126aeb16a6a13f73a77f91491c/6d09e/universalaim.webp 600w","type":"image/webp","sizes":"(min-width: 600px) 600px, 100vw"}]},"width":600,"height":600}}},"status":"active","tags":["Industry funding"],"title":"Deep learning and multi-modal models for the music industry","author":"Dr George Fazekas (PI)","begin":"2019","end":"2023","grant":"Universal Music Group International Limited, AIM CDT PhD studentship","amount":"£54,000 ","link":"https://www.aim.qmul.ac.uk/"},"id":"dc44fa3d-b999-52c0-a3fa-d9dd8f683ec1"}]},"allTags":{"group":[{"fieldValue":"Industry funding","totalCount":17},{"fieldValue":"Internal funding","totalCount":1},{"fieldValue":"UK national academy funding","totalCount":4},{"fieldValue":"UKRI funding","totalCount":13}]}}}