{"componentChunkName":"component---src-templates-archive-post-js","path":"/archive/WANCM-programme/","result":{"data":{"markdownRemark":{"html":"<p>Research workshop, QMUL, London<br>\nWed 17th February 2016, 9:30am-5pm</p>\n<h2>Workshop Programme</h2>\n<p><strong><a href=\"WANCM_programme.pdf\">Workshop book of abstracts (PDF)</a></strong></p>\n<p><strong>KEYNOTE TALKS:</strong> (click on titles for abstracts)</p>\n<ul>\n<li>\n<p><a href=\"http://pure.au.dk/portal/en/persons/elvira-brattico%28a3b2de17-4a92-4c08-8022-785886ff63df%29.html\">Prof Elvira Brattico</a> <em>(Aarhus University)</em>, 10:10-11:10<br>\n<a href=\"keynotes.html#keynote1\">Automatic and conscious processing of musical sound features in the brain</a> <a href=\"https://ess.q-review.qmul.ac.uk/ess/echo/presentation/62e5be62-19fe-440d-8ca2-b9bd91a8b582\">[VIDEO]</a></p>\n</li>\n<li>\n<p><a href=\"http://cream.ircam.fr\">Dr Jean-Julien Aucouturier</a> <em>(CNRS/IRCAM)</em>, 13:30-14:30<br>\n<a href=\"keynotes.html#keynote2\">Real-time transformations of emotional speech alter speaker's emotions in a congruent direction</a> <a href=\"https://ess.q-review.qmul.ac.uk/ess/echo/presentation/8a2f3fc6-333b-411c-8100-10b7ea4b63a5\">[VIDEO]</a></p>\n</li>\n<li>\n<p><a href=\"http://cbl.eng.cam.ac.uk/Public/Turner/Turner\">Dr Richard E. Turner</a> <em>(University of Cambridge)</em>, 16:00-17:00<br>\n<a href=\"keynotes.html#keynote3\">Probabilistic models for natural audio signals</a> <a href=\"https://ess.q-review.qmul.ac.uk/ess/echo/presentation/0388a0d3-da5e-47b6-a6c5-53e89f42a7da\">[VIDEO]</a></p>\n</li>\n</ul>\n<p><strong>ORAL PRESENTATIONS - SESSION 1</strong> (11:10-12:10)</p>\n<ul>\n<li>\n<p>High-level influences on auditory streaming <a href=\"https://ess.q-review.qmul.ac.uk/ess/echo/presentation/a77f9c42-86e1-475a-a139-2c7c7fe91b38\">[VIDEO]</a><br>\nAlexander J. Billig, Matthew H. Davis, Robert P. Carlyon</p>\n</li>\n<li>\n<p>Multiple hypothesis testing on partial coherences: Graphical modelling of Neurological data in EEG/MEG <a href=\"https://ess.q-review.qmul.ac.uk/ess/echo/presentation/24630b3d-6c0d-469b-85ab-992d12d0d30f\">[VIDEO]</a><br>\nDeborah Schneider-Luftman</p>\n</li>\n<li>\n<p>EEG-based Emotion Detection in Music Listening <a href=\"https://ess.q-review.qmul.ac.uk/ess/echo/presentation/913935f1-b924-446b-9dac-a5402ce926b7\">[VIDEO]</a><br>\nRafael Ramirez, Zacharias Vamvakousis, Sergio Giraldo</p>\n</li>\n</ul>\n<p><strong>ORAL PRESENTATIONS - SESSION 2</strong> (14:30-15:30)</p>\n<ul>\n<li>\n<p>Investigating the role of auditory and cognitive factors for various speech-perception-in-noise situations in older listeners <a href=\"https://ess.q-review.qmul.ac.uk/ess/echo/presentation/c6c40313-ab4c-4682-9cc3-5884ae96d427\">[VIDEO]</a><br>\nSarah Knight and Antje Heinrich</p>\n</li>\n<li>\n<p>Contextual effects on the neural encoding of speech sounds <a href=\"https://ess.q-review.qmul.ac.uk/ess/echo/presentation/e2676b0d-a129-4f48-b7c1-fe5cc1d6e176\">[VIDEO]</a><br>\nS. Rutten, R. Santoro, A. Hervais-Adelman, E. Formisano, and N. Golestani</p>\n</li>\n<li>\n<p>Phonological Model for Automatic Recognition of Continuous Speech <a href=\"https://ess.q-review.qmul.ac.uk/ess/echo/presentation/ed74caa7-8227-4315-bc58-94883f9fbaa9\">[VIDEO]</a><br>\nVipul Arora, Aditi Lahiri and Henning Reetz</p>\n</li>\n</ul>\n<p><strong>POSTER PRESENTATIONS</strong> (12:10-13:30, 15:30-16:00)</p>\n<ul>\n<li>\n<p>Shared acoustic codes underlie emotional communication in Music and Speech – Evidence from Machine Learning<br>\nEduardo Coutinho</p>\n</li>\n<li>\n<p>Analysis of spectral correlates of violin timbre quality in relation to experts’ subjective ratings<br>\nEwa Łukasik</p>\n</li>\n<li>\n<p>Analysis of envelope following responses to natural vowels using a Fourier analyzer<br>\nFrederique J Vanheusden, Steven L Bell and David M Simpson</p>\n</li>\n<li>\n<p>Feature Extraction Based on Auditory Image Model for Noise-Robust Automatic Speech Recognition<br>\nX. Yang, M. Karbasi, S. Bleeck, and D. Kolossa</p>\n</li>\n<li>\n<p>Adaptive Frequency Neural Networks for Dynamic Pulse and Metre Perception<br>\nAndrew Lambert, Tillman Weyde, and Newton Armstrong</p>\n</li>\n<li>\n<p>Compensation for spectral and temporal envelope distortion caused by transmission channel acoustics<br>\nCleo Pike, Amy V Beeston, Tim Brookes, Guy J Brown, and Russell Mason</p>\n</li>\n<li>\n<p>Using auditory brainstem responses (ABRs) to measure hearing loss-induced increases in neural gain and its implications with tinnitus<br>\nA.J Hardy, J. de Boer, and Katrin Krumbholz</p>\n</li>\n<li>\n<p>A mobile-based platform for evaluating localisation of virtual sound sources (poster+demo)<br>\nMark Steadman and Lorenzo Picinali</p>\n</li>\n<li>\n<p>A model-based EEG approach for investigating the hierarchical nature of continuous speech processing<br>\nGiovanni M. Di Liberto, Michael J. Crosse, and Edmund C. Lalor</p>\n</li>\n<li>\n<p>Towards a Library of Musical Core-Signals<br>\nClara Hollomey</p>\n</li>\n<li>\n<p>Functional neural modelling of just noticeable difference in interaural time detection for normal hearing and bilateral cochlear implant users<br>\nAndreas N. Prokopiou, Jan Wouters, and Tom Francart</p>\n</li>\n<li>\n<p>Sensitivity to the statistics of rapid, stochastic tone sequences<br>\nSijia Zhao, Marcus Pearce, Fred Dick, and Maria Chait</p>\n</li>\n<li>\n<p>A meta-analysis and systematic review of perceptual studies of high resolution audio discrimination<br>\nJoshua D. Reiss</p>\n</li>\n<li>\n<p>Does adaptation sharpen frequency representation in auditory cortex?<br>\nOscar Woolnough, Jessica de Boer, Katrin Krumbholz, Rob Mill, and Chris Sumner</p>\n</li>\n<li>\n<p>Perceiving auditory streams for instrumental and vocal music: the effects of prior knowledge and frequency separation<br>\nSandra Quinn and Eliza Mclaughlin</p>\n</li>\n<li>\n<p>Stimulus predictability dynamically modulates neural gain in the auditory processing stream<br>\nRyszard Auksztulewicz, Nicolas Barascud, Gerald Cooray, Maria Chait, and Karl Friston</p>\n</li>\n<li>\n<p>Automatic identification of musical schemata via symbolic fingerprinting and temporal filters<br>\nAndreas Katsiavalos, Tom Collins, and Bret Battey</p>\n</li>\n<li>\n<p>Can the non-human primate core-belt model be applied to the human auditory cortex? Evidence from functional and structural MRI at 7 Tesla<br>\nJulien Besle, Olivier Mougin, Rosa Sanchez-Panchuelo, Penny Gowland, Richard Bowtell, Sue Francis, and Katrin Krumbholz</p>\n</li>\n<li>\n<p>Validation of a new open-source platform for real-time emotional speech transformation<br>\nLaura Rachman</p>\n</li>\n<li>\n<p>The reduced GABA concentration with absolute pitch possessors revealed by Magnetic resonance spectroscopy<br>\nTomoya Nakai, Hiroaki Maeshima, Chihiro Hosoda, and Kazuo Okanoya</p>\n</li>\n<li>\n<p>Rising to the challenge: modelling transfer learning of polyphonic musical structure<br>\nReinier de Valk and Tillman Weyde</p>\n</li>\n<li>\n<p>Comparison of reaction time measurement and Yes/no question paradigm regarding the perception of spatial coherence<br>\nHanne Stenzel and Philip J. B. Jackson</p>\n</li>\n<li>\n<p>EEG-powered Soundtrack for Interactive Theatre<br>\nGrigore Burloiu, Alexandru Berceanu, and Cătălin Crețu</p>\n</li>\n</ul>\n<p><strong><a href=\"../WANCM\">Back to main workshop webpage</a></strong></p>","frontmatter":{"title":"Workshop on Auditory Neuroscience, Cognition and Modelling 2016","image":null}}},"pageContext":{"slug":"/archive/WANCM-programme","breadcrumb":{"location":"/archive/WANCM-programme/","crumbs":[{"pathname":"/","crumbLabel":"Home"},{"pathname":"/archive","crumbLabel":"archive"},{"pathname":"/archive/WANCM-programme","crumbLabel":"WANCM-programme"}]}}},"staticQueryHashes":["537410583"],"slicesMap":{}}